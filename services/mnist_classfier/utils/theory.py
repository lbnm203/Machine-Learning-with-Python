import numpy as np
from sklearn.datasets import fetch_openml
import streamlit as st
import matplotlib.pyplot as plt


def visualize_mnist(X, y):
    unique_labels = np.unique(y)
    images = []

    # L·∫•y m·ªôt ·∫£nh cho m·ªói nh√£n t·ª´ 0 ƒë·∫øn 9
    for label in unique_labels:
        idx = np.nonzero(y == label)[0][0]  # L·∫•y index ƒë·∫ßu ti√™n c·ªßa label
        images.append((X[idx], label))

    fig, axes = plt.subplots(2, 5, figsize=(7, 3))
    # fig.suptitle("Nh·ªØng nh√£n trong t·∫≠p d·ªØ li·ªáu MNIST", fontsize=10)

    for i, ax in enumerate(axes.flat):
        ax.imshow(images[i][0].reshape(28, 28), cmap="gray")
        ax.set_title(f"Label: {images[i][1]}")
        ax.axis("off")

    st.pyplot(fig)


# @st.cache_data
@st.cache_data
def mnist_dataset():

    st.markdown("## üìú T·∫≠p d·ªØ li·ªáu MNIST")
    st.write("---")

    mnist = fetch_openml('mnist_784', version=1, as_frame=False)
    X, y = mnist["data"], mnist["target"]

    # chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu
    X = X.astype(np.float32)
    y = y.astype(np.int64)

    col1, col2 = st.columns(2)
    with col1:
        visualize_mnist(X, y)

    with col2:
        st.markdown("""
            **MNIST (Modified National Institute of Standards and Technology)** l√† m·ªôt trong
            nh·ªØng t·∫≠p d·ªØ li·ªáu ph·ªï bi·∫øn nh·∫•t trong lƒ©nh v·ª±c nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay. ƒê√¢y
            l√† m·ªôt t·∫≠p d·ªØ li·ªáu ti√™u chu·∫©n ƒë·ªÉ hu·∫•n luy·ªán v√† ƒë√°nh gi√° c√°c m√¥ h√¨nh machine
            learning (ML) v√† deep learning (DL), ƒë·∫∑c bi·ªát l√† c√°c m√¥ h√¨nh nh·∫≠n d·∫°ng h√¨nh ·∫£nh.

            MNIST g·ªìm 70.000 ·∫£nh ch·ªØ s·ªë vi·∫øt tay v·ªõi k√≠ch th∆∞·ªõc ·∫£nh 28x28 pixel, ·∫£nh grayscale(ƒëen tr·∫Øng, 1 k√™nh m√†u)
            - 60.000 ·∫£nh d√πng ƒë·ªÉ hu·∫•n luy·ªán (training set)
            - 10.000 ·∫£nh d√πng ƒë·ªÉ ƒë√°nh gi√° (test set)

            - S·ªë l·ªõp (s·ªë nh√£n): 10 (c√°c ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9)

            M·ªói ·∫£nh ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ma tr·∫≠n 28x28

            Ta s·∫Ω chu·∫©n h√≥a d·ªØ li·ªáu, ƒë∆∞a gi√° tr·ªã pixel ban ƒë·∫ßu n·∫±m trong kho·∫£ng [0, 255],
            c·∫ßn chia cho 255.0 ƒë·ªÉ ƒë∆∞a v·ªÅ kho·∫£ng [0,1]
        """)

    # Visualize target distribution
    fig, ax = plt.subplots(figsize=(7, 3))
    unique, counts = np.unique(y, return_counts=True)
    ax.bar(unique, counts, tick_label=unique)
    ax.set_title("Ph√¢n ph·ªëi c√°c nh√£n trong t·∫≠p d·ªØ li·ªáu MNIST")
    ax.set_xlabel("Nh√£n")
    ax.set_ylabel("S·ªë l∆∞·ª£ng")
    st.pyplot(fig)

    st.write("---")

    return X, y


def decision_tree_theory():
    # Ti√™u ƒë·ªÅ ch√≠nh
    st.header("Thu·∫≠t to√°n Decision Tree (C√¢y Quy·∫øt ƒê·ªãnh)")
    st.write("""
    - **Decision Tree** l√† m·ªôt thu·∫≠t to√°n h·ªçc m√°y d√πng cho c·∫£ ph√¢n lo·∫°i v√† h·ªìi quy. N√≥ chia d·ªØ li·ªáu th√†nh c√°c v√πng d·ª±a tr√™n c√°c ƒëi·ªÅu ki·ªán quy·∫øt ƒë·ªãnh, ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng c·∫•u tr√∫c c√¢y v·ªõi n√∫t g·ªëc, n√∫t n·ªôi b·ªô, v√† n√∫t l√°.

    - **·ª®ng d·ª•ng**: Ph√¢n lo·∫°i email, d·ª± ƒëo√°n gi√° nh√†, ch·∫©n ƒëo√°n y khoa.
    """)

    col1, col2 = st.columns(2)
    with col1:

        # Ph·∫ßn 1: C√°c kh√°i ni·ªám c∆° b·∫£n
        st.subheader("C√°c kh√°i ni·ªám c∆° b·∫£n")
        st.write("""
        - **ƒê·∫∑c tr∆∞ng (Feature)**: C√°c bi·∫øn ƒë·∫ßu v√†o (v√≠ d·ª•: tu·ªïi, thu nh·∫≠p).
        - **Nh√£n (Label)**: Bi·∫øn ƒë·∫ßu ra c·∫ßn d·ª± ƒëo√°n (v√≠ d·ª•: C√≥/Kh√¥ng).
        - **ƒê·ªô kh√¥ng thu·∫ßn khi·∫øt (Impurity)**: M·ª©c ƒë·ªô h·ªón t·∫°p c·ªßa d·ªØ li·ªáu trong m·ªôt n√∫t.
        - **Chia nh√°nh (Splitting)**: Qu√° tr√¨nh chia d·ªØ li·ªáu d·ª±a tr√™n m·ªôt ƒëi·ªÅu ki·ªán.
        """)

        # Ph·∫ßn 2: C√°ch ho·∫°t ƒë·ªông
        st.subheader("C√°ch ho·∫°t ƒë·ªông c·ªßa Decision Tree")
        st.write("""
        1. **Ch·ªçn ƒë·∫∑c tr∆∞ng v√† ng∆∞·ª°ng t·ªët nh·∫•t**:
            - Duy·ªát qua c√°c ƒë·∫∑c tr∆∞ng v√† gi√° tr·ªã ƒë·ªÉ t√¨m c√°ch chia gi·∫£m ƒë·ªô kh√¥ng thu·∫ßn khi·∫øt nhi·ªÅu nh·∫•t.
        2. **Chia d·ªØ li·ªáu**:
            - D·ªØ li·ªáu ƒë∆∞·ª£c chia th√†nh c√°c nh√°nh d·ª±a tr√™n ƒëi·ªÅu ki·ªán (v√≠ d·ª•: "tu·ªïi ‚â§ 30").
        3. **L·∫∑p l·∫°i**:
            - Ti·∫øp t·ª•c chia tr√™n m·ªói nh√°nh cho ƒë·∫øn khi ƒë·∫°t ƒëi·ªÅu ki·ªán d·ª´ng (thu·∫ßn khi·∫øt, ƒë·ªô s√¢u t·ªëi ƒëa, s·ªë m·∫´u t·ªëi thi·ªÉu).
        4. **G√°n gi√° tr·ªã n√∫t l√°**:
            - Ph√¢n lo·∫°i: Ch·ªçn nh√£n ph·ªï bi·∫øn nh·∫•t.
            - H·ªìi quy: Ch·ªçn gi√° tr·ªã trung b√¨nh.
        """)

    with col2:

        # Ph·∫ßn 3: C√¥ng th·ª©c to√°n h·ªçc
        st.subheader("C√¥ng th·ª©c to√°n h·ªçc")

        st.markdown("""
        #### Gini Index (Ph√¢n lo·∫°i)
        - **ƒêo ƒë·ªô kh√¥ng thu·∫ßn khi·∫øt:** """)

        st.latex(r"\text{Gini} = 1 - \sum_{i=1}^{c} p_i^2")
        st.write("""
        - $p_i$: T·ª∑ l·ªá m·∫´u thu·ªôc l·ªõp i.

        - $c$: S·ªë l·ªõp.
        """)

        st.write("""
        #### Entropy v√† Information Gain (Ph√¢n lo·∫°i)

        - **Entropy**:
        """)

        st.latex(r"\text{Entropy} = - \sum_{i=1}^{c} p_i \log_2(p_i)")

        st.write("- **Information Gain**:")

        st.latex(
            r"\text{IG} = \text{Entropy(parent)} - \sum_{j} \frac{N_j}{N} \text{Entropy(child}_j\text{)}")

        st.write("#### Mean Squared Error (H·ªìi quy)")

        st.latex(r"\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \bar{y})^2")

        st.markdown(r"""
        - $y_i$: Gi√° tr·ªã th·ª±c t·∫ø.
                    
        - $\bar{y}$: Gi√° tr·ªã trung b√¨nh.
                    
        """)

    # # Ph·∫ßn 4: V√≠ d·ª• minh h·ªça
    # st.subheader("V√≠ d·ª• minh h·ªça")
    # st.write("""
    # Gi·∫£ s·ª≠ d·ªØ li·ªáu c√≥ 2 ƒë·∫∑c tr∆∞ng: "Tu·ªïi" v√† "Thu nh·∫≠p", nh√£n l√† "Mua nh√†" (C√≥/Kh√¥ng):
    # - B∆∞·ªõc 1: T√≠nh Gini cho to√†n b·ªô d·ªØ li·ªáu.
    # - B∆∞·ªõc 2: Chia v·ªõi "Tu·ªïi ‚â§ 30":
    #     - Nh√°nh ‚â§ 30: 80% Kh√¥ng, 20% C√≥.
    #     - Nh√°nh > 30: 60% C√≥, 40% Kh√¥ng.
    # - B∆∞·ªõc 3: Ch·ªçn "Tu·ªïi ‚â§ 30" l√†m n√∫t g·ªëc n·∫øu Gini gi·∫£m nhi·ªÅu.
    # - B∆∞·ªõc 4: Ti·∫øp t·ª•c chia tr√™n nh√°nh v·ªõi "Thu nh·∫≠p".
    # """)

    with col1:
        # Ph·∫ßn 5: ∆Øu v√† nh∆∞·ª£c ƒëi·ªÉm
        st.subheader("∆Øu v√† nh∆∞·ª£c ƒëi·ªÉm")
        st.write("""
        **∆Øu ƒëi·ªÉm**:
        - D·ªÖ hi·ªÉu, tr·ª±c quan.
        - Kh√¥ng c·∫ßn chu·∫©n h√≥a d·ªØ li·ªáu.
        - X·ª≠ l√Ω ƒë∆∞·ª£c c·∫£ d·ªØ li·ªáu s·ªë v√† ph√¢n lo·∫°i.

        **Nh∆∞·ª£c ƒëi·ªÉm**:
        - D·ªÖ b·ªã overfitting n·∫øu kh√¥ng gi·ªõi h·∫°n ƒë·ªô s√¢u.
        - Nh·∫°y c·∫£m v·ªõi nhi·ªÖu v√† d·ªØ li·ªáu m·∫•t c√¢n b·∫±ng.
        - Kh√¥ng t·ªët v·ªõi m·ªëi quan h·ªá phi tuy·∫øn ph·ª©c t·∫°p.
        """)


def svm_theory():
    pass


def theory_info():
    st.title("Th√¥ng tin v·ªÅ c√°c thu·∫≠t to√°n")
    st.markdown("""
    - Decision Tree: Thu·∫≠t to√°n d·ª± ƒëo√°n gi√° tr·ªã ƒë·∫ßu ra d·ª±a tr√™n c√°c c√¢y quy·∫øt ƒë·ªãnh.
    - Support Vector Machine (SVM): Thu·∫≠t to√°n h·ªçc m√°y t√≠nh ƒë·∫∑c tr∆∞ng (SVM) cho ph√¢n l·ªõp hai ho·∫∑c nhi·ªÅu l·ªõp.
    """)
