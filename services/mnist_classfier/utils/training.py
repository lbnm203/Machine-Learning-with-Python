import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import mlflow
from mlflow.tracking import MlflowClient

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import os
from sklearn.model_selection import cross_val_score


def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/lbnm203/Machine_Learning_UI.mlflow"
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    os.environ["MLFLOW_TRACKING_USERNAME"] = "lbnm203"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "0902d781e6c2b4adcd3cbf60e0f288a8085c5aab"

    mlflow.set_experiment("MNIST_Classification")


def train_process(X, y):
    mlflow_input()
    st.write("## ‚öôÔ∏è Qu√° tr√¨nh hu·∫•n luy·ªán")

    total_samples = X.shape[0]

    # Thanh k√©o ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train
    num_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train:",
                            1000, total_samples, 10000)

    st.session_state.total_samples = num_samples
    # Thanh k√©o ch·ªçn t·ª∑ l·ªá Train/Test
    test_size = st.slider("Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20)
    val_size = st.slider("Ch·ªçn % d·ªØ li·ªáu Validation", 0, 50,
                         10)  # X√°c ƒë·ªãnh tr∆∞·ªõc khi s·ª≠ d·ª•ng

    remaining_size = 100 - test_size  # S·ª≠a l·ªói: S·ª≠ d·ª•ng test_size thay v√¨ train_size

    # Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh theo y√™u c·∫ßu
    X_selected, _, y_selected, _ = train_test_split(
        X, y, train_size=num_samples, stratify=y, random_state=42
    )

    # Chia train/test theo t·ª∑ l·ªá ƒë√£ ch·ªçn
    stratify_option = y_selected if len(np.unique(y_selected)) > 1 else None
    X_train_full, X_test, y_train_full, y_test = train_test_split(
        X_selected, y_selected, test_size=test_size/100, stratify=stratify_option, random_state=42
    )

    # Chia train/val theo t·ª∑ l·ªá ƒë√£ ch·ªçn
    stratify_option = y_train_full if len(
        np.unique(y_train_full)) > 1 else None
    X_train, X_val, y_train, y_val = train_test_split(
        X_train_full, y_train_full, test_size=val_size / remaining_size,
        stratify=stratify_option, random_state=42
    )

    # L∆∞u v√†o session_state
    st.session_state.X_train = X_train
    st.session_state.X_val = X_val
    st.session_state.X_test = X_test
    st.session_state.y_train = y_train
    st.session_state.y_val = y_val
    st.session_state.y_test = y_test
    st.session_state.test_size = X_test.shape[0]
    st.session_state.val_size = X_val.shape[0]
    st.session_state.train_size = X_train.shape[0]

    if "X_train" in st.session_state:
        X_train = st.session_state.X_train
        X_val = st.session_state.X_val
        X_test = st.session_state.X_test
        y_train = st.session_state.y_train
        y_val = st.session_state.y_val
        y_test = st.session_state.y_test

    # st.write(f'Training: {X_train.shape[0]} - Testing: {y_test.shape[0]}')

    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0

    table_size = pd.DataFrame({
        'Dataset': ['Train', 'Validation', 'Test'],
        'K√≠ch th∆∞·ªõc (%)': [remaining_size - val_size, val_size, test_size],
        'S·ªë l∆∞·ª£ng m·∫´u': [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
    })
    st.write(table_size)

    st.write("---")

    # üìå **Ch·ªçn m√¥ h√¨nh**
    model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh:", ["Decision Tree", "SVM"])

    if model_choice == "Decision Tree":
        st.markdown("""
        - **Tham s·ªë m√¥ h√¨nh:**  
            - **max_depth**: ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa c√¢y.  
                - **Gi√° tr·ªã nh·ªè**: Tr√°nh overfitting nh∆∞ng c√≥ th·ªÉ underfitting.  
                - **Gi√° tr·ªã l·ªõn**: D·ªÖ b·ªã overfitting v√¨ kh√≥ h·ªçc ƒë∆∞·ª£c c√°c m·∫´u ph·ª©c t·∫°p trong d·ªØ li·ªáu 
        """)
        st.markdown("""- criterion: x√°c ƒë·ªãnh c√°ch th·ª©c c√¢y quy·∫øt ƒë·ªãnh ch·ªçn thu·ªôc t√≠nh ƒë·ªÉ ph√¢n nh√°nh""", help="""
- Gini:
    - M·ª•c ti√™u c·ªßa Gini l√† ch·ªçn thu·ªôc t√≠nh ph√¢n nh√°nh sao cho d·ªØ li·ªáu sau khi chia c√≥ ƒë·ªô thu·∫ßn khi·∫øt cao nh·∫•t.
    - N·∫øu m·ªôt node ch·ªâ ch·ª©a m·∫´u c·ªßa m·ªôt l·ªõp duy nh·∫•t, gi√° tr·ªã Gini s·∫Ω l√† 0 (thu·∫ßn khi·∫øt ho√†n to√†n).
    - N·∫øu m·ªôt node ch·ª©a m·∫´u c·ªßa nhi·ªÅu l·ªõp kh√°c nhau, gi√° tr·ªã Gini s·∫Ω tƒÉng.
- Entropy:
    - M·ª•c ti√™u c·ªßa entropy l√† ch·ªçn thu·ªôc t√≠nh ph√¢n nh√°nh sao cho ƒë·ªô kh√¥ng ch·∫Øc ch·∫Øn c·ªßa d·ªØ li·ªáu gi·∫£m nhi·ªÅu nh·∫•t.
    - Entropy c√†ng cao ‚ü∂ D·ªØ li·ªáu c√†ng h·ªón lo·∫°n (√≠t thu·∫ßn khi·∫øt).
    - Entropy c√†ng th·∫•p ‚ü∂ D·ªØ li·ªáu c√†ng thu·∫ßn khi·∫øt.
 """)
        st.markdown("- min_samples_leaf (S·ªë l∆∞·ª£ng m·∫´u t·ªëi thi·ªÉu trong m·ªói l√°) ", help="""
- M·ª•c ti√™u l√† quy ƒë·ªãnh s·ªë l∆∞·ª£ng m·∫´u nh·ªè nh·∫•t m√† m·ªôt node l√° c√≥ th·ªÉ c√≥.
- N·∫øu m·ªôt node c√≥ √≠t h∆°n min_samples_leaf m·∫´u, n√≥ s·∫Ω b·ªã h·ª£p nh·∫•t v·ªõi node cha thay v√¨ tr·ªü th√†nh m·ªôt node l√°.
- Gi√∫p tr√°nh overfitting b·∫±ng c√°ch ngƒÉn c√¢y quy·∫øt ƒë·ªãnh qu√° ph·ª©c t·∫°p.
""")

        max_depth = st.slider("max_depth", 1, 20, 5)
        criterion = st.selectbox("Ch·ªçn ti√™u ch√≠ ph√¢n nh√°nh (criterion)", [
            "gini", "entropy"], index=0)
        min_samples_leaf = st.slider(
            "S·ªë l∆∞·ª£ng m·∫´u t·ªëi thi·ªÉu tr√™n m·ªói l√° (min_samples_leaf)", 1, 10, 2)
        model = DecisionTreeClassifier(
            max_depth=max_depth, criterion=criterion, min_samples_leaf=min_samples_leaf)

    elif model_choice == "SVM":
        st.markdown("""
        - **Tham s·ªë m√¥ h√¨nh:**  
            - **C (Regularization)**: H·ªá s·ªë ƒëi·ªÅu ch·ªânh ƒë·ªô ph·∫°t l·ªói.  
                - **C nh·ªè**: M√¥ h√¨nh ƒë∆°n gi·∫£n h∆°n, ch·∫•p nh·∫≠n nhi·ªÅu l·ªói h∆°n.  
                - **C l·ªõn**: M√¥ h√¨nh c·ªë g·∫Øng ph√¢n lo·∫°i ch√≠nh x√°c m·ªçi ƒëi·ªÉm, nh∆∞ng d·ªÖ b·ªã overfitting.  
            - **Kernel**: H√†m kernel trick gi√∫p ph√¢n t√°ch d·ªØ li·ªáu phi tuy·∫øn t√≠nh b·∫±ng c√°ch √°nh x·∫° d·ªØ 
                li·ªáu v√†o kh√¥ng gian c√≥ nhi·ªÅu chi·ªÅu h∆°n.
                - Linear: M√¥ h√¨nh d√πng si√™u ph·∫≥ng tuy·∫øn t√≠nh ƒë·ªÉ ph√¢n l·ªõp.  
                - RBF: Kernel Gaussian Radial Basis Function gi√∫p ph√¢n t√°ch d·ªØ li·ªáu phi tuy·∫øn t√≠nh t·ªët h∆°n.  
                - Poly: S·ª≠ d·ª•ng ƒëa th·ª©c b·∫≠c cao ƒë·ªÉ ph√¢n l·ªõp, ph√π h·ª£p v·ªõi d·ªØ li·ªáu c√≥ m·ªëi quan h·ªá ph·ª©c t·∫°p.  
                - Sigmoid: M√¥ ph·ªèng h√†m k√≠ch ho·∫°t c·ªßa m·∫°ng n∆°-ron.
 
        """)
        C = st.slider("C (Regularization)", 0.1, 10.0, 1.0)
        kernel = st.selectbox("Kernel", ["linear", "rbf", "poly", "sigmoid"])
        model = SVC(C=C, kernel=kernel)

    n_folds = st.slider("Ch·ªçn s·ªë folds Cross-Validation:",
                        min_value=2, max_value=10, value=3)

    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
            mlflow.log_param("test_size", st.session_state.test_size)
            mlflow.log_param("val_size", st.session_state.val_size)
            mlflow.log_param("train_size", st.session_state.train_size)
            mlflow.log_param("num_samples", st.session_state.total_samples)

            cv_scores = cross_val_score(model, X_train, y_train, cv=n_folds)
            mean_cv_score = cv_scores.mean()
            std_cv_score = cv_scores.std()

            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            acc = accuracy_score(y_test, y_pred)
            st.success(f"ƒê·ªô ch√≠nh x√°c tr√™n Testing: {acc:.4f}")
            st.success(
                f"ƒê·ªô ch√≠nh x√°c trung b√¨nh khi Cross-Validation: {mean_cv_score:.4f}                                                     ")

            mlflow.log_param("model", model_choice)
            if model_choice == "Decision Tree":
                mlflow.log_param("max_depth", max_depth)
            elif model_choice == "SVM":
                mlflow.log_param("C", C)
                mlflow.log_param("kernel", kernel)

            mlflow.log_metric("test_accuracy", acc)
            mlflow.log_metric("cv_accuracy_mean", mean_cv_score)
            mlflow.log_metric("cv_accuracy_std", std_cv_score)
            mlflow.sklearn.log_model(model, model_choice.lower())

            st.success("L∆∞u tham s·ªë v√†o MLflow th√†nh c√¥ng!")

        if model_choice == "Decision Tree":
            depths = range(1, 21)
            accuracies = []
            for depth in depths:
                model = DecisionTreeClassifier(
                    max_depth=max_depth, criterion=criterion, min_samples_leaf=min_samples_leaf)
                model.fit(X_train, y_train)
                y_temp_pred = model.predict(X_test)
                temp_acc = accuracy_score(y_test, y_temp_pred)
                accuracies.append(temp_acc)

            mlflow.log_param("criterion", criterion)
            mlflow.log_param("min_samples_leaf", min_samples_leaf)

            # st.write("ƒê·ªô ch√≠nh x√°c qua t·ª´ng ƒë·ªô s√¢u ")
            # accuracy_df = pd.DataFrame(
            #     {"ƒê·ªô s√¢u": depths, "ƒê·ªô ch√≠nh x√°c": accuracies})
            # st.line_chart(accuracy_df.set_index("ƒê·ªô s√¢u"))

        # st.success(f"‚úÖ ƒê·ªô ch√≠nh x√°c: {temp_acc:.4f}")

        # model.fit(X_train, y_train)
        # y_pred = model.predict(X_test)
        # acc = accuracy_score(y_test, y_pred)
        # st.success(f"‚úÖ ƒê·ªô ch√≠nh x√°c: {acc:.4f}")

        # L∆∞u m√¥ h√¨nh v√†o session_state d∆∞·ªõi d·∫°ng danh s√°ch n·∫øu ch∆∞a c√≥
        if "models" not in st.session_state:
            st.session_state["models"] = []

        # T·∫°o t√™n m√¥ h√¨nh d·ª±a tr√™n l·ª±a ch·ªçn m√¥ h√¨nh v√† kernel
        model_name = model_choice.lower().replace(" ", "_")
        if model_choice == "SVM":
            model_name += f"_{kernel}"

        # Ki·ªÉm tra n·∫øu t√™n m√¥ h√¨nh ƒë√£ t·ªìn t·∫°i trong session_state
        existing_model = next(
            (item for item in st.session_state["models"] if item["name"] == model_name), None)

        if existing_model:
            # T·∫°o t√™n m·ªõi v·ªõi s·ªë ƒë·∫øm ph√≠a sau
            count = 1
            new_model_name = f"{model_name}_{count}"

            # Ki·ªÉm tra t√™n m·ªõi ch∆∞a t·ªìn t·∫°i
            while any(item["name"] == new_model_name for item in st.session_state["models"]):
                count += 1
                new_model_name = f"{model_name}_{count}"

            # S·ª≠ d·ª•ng t√™n m·ªõi ƒë√£ t·∫°o
            model_name = new_model_name
            # st.warning(f"‚ö†Ô∏è M√¥ h√¨nh ƒë∆∞·ª£c l∆∞u v·ªõi t√™n l√†: {model_name}")

        # # L∆∞u m√¥ h√¨nh v√†o danh s√°ch v·ªõi t√™n m√¥ h√¨nh c·ª• th·ªÉ
        st.session_state["models"].append({"name": model_name, "model": model})
        st.success(
            f"Log d·ªØ li·ªáu **{st.session_state['models']}** th√†nh c√¥ng!")
        # st.write(f"üîπ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v·ªõi t√™n: {model_name}")
        # st.write(
        #     f"T·ªïng s·ªë m√¥ h√¨nh hi·ªán t·∫°i: {len(st.session_state['models'])}")

        # # In t√™n c√°c m√¥ h√¨nh ƒë√£ l∆∞u
        # st.write("üìã Danh s√°ch c√°c m√¥ h√¨nh ƒë√£ l∆∞u:")
        model_names = [model["name"] for model in st.session_state["models"]]
        # # Hi·ªÉn th·ªã t√™n c√°c m√¥ h√¨nh trong m·ªôt d
        # st.write(", ".join(model_names))

        # st.success("L∆∞u th√†nh c√¥ng!")

        # st.markdown(
        #     f"üîó [Truy c·∫≠p MLflow UI MNIST_Classification ƒë·ªÉ xem tham s·ªë]({st.session_state['mlflow_url']})")
