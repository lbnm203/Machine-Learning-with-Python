import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import mlflow
from mlflow.tracking import MlflowClient

from sklearn.model_selection import train_test_split,  StratifiedKFold
import os
import mlflow.keras
from tensorflow import keras
import time
import datetime
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from stqdm import stqdm


def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/lbnm203/Machine_Learning_UI.mlflow"
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    os.environ["MLFLOW_TRACKING_USERNAME"] = "lbnm203"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "0902d781e6c2b4adcd3cbf60e0f288a8085c5aab"

    mlflow.set_experiment("MNIST_Neural_Network_Label")

# H√†m t·∫°o model


def create_model(input_shape, num_classes, hidden1_size, hidden2_size, dropout_rate, activ_hd_1, activ_hd_2, learning_rate):
    model = keras.Sequential([
        layers.Flatten(input_shape=input_shape),
        layers.Dense(hidden1_size, activation=activ_hd_1),
        layers.Dropout(dropout_rate),
        layers.Dense(hidden2_size, activation=activ_hd_2),
        layers.Dropout(dropout_rate),
        layers.Dense(num_classes, activation='softmax')
    ])

    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer,
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# H√†m l·∫•y d·ªØ li·ªáu ban ƒë·∫ßu


def get_initial_labeled_data(X, y, percentage):
    num_classes = len(np.unique(y))
    X_labeled = []
    y_labeled = []

    for class_id in range(num_classes):
        class_indices = np.where(y == class_id)[0]
        num_samples = int(len(class_indices) * percentage)
        selected_indices = np.random.choice(
            class_indices, num_samples, replace=False)

        X_labeled.append(X[selected_indices])
        y_labeled.append(y[selected_indices])

    return np.concatenate(X_labeled), np.concatenate(y_labeled)

# H√†m visualize k·∫øt qu·∫£


def visualize_results(history):
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 4))

    # V·∫Ω accuracy
    ax1.plot(history['train_acc'], label='Train Accuracy')
    ax1.plot(history['val_acc'], label='Validation Accuracy')
    ax1.plot(history['test_acc'], label='Test Accuracy')
    ax1.set_title('Model Accuracy')
    ax1.set_xlabel('Iteration')
    ax1.set_ylabel('Accuracy')
    ax1.legend()

    # # V·∫Ω loss
    # ax2.plot(history['train_loss'], label='Train Loss')
    # ax2.plot(history['val_loss'], label='Validation Loss')
    # ax2.plot(history['test_loss'], label='Test Loss')
    # ax2.set_title('Model Loss')
    # ax2.set_xlabel('Iteration')
    # ax2.set_ylabel('Loss')
    # ax2.legend()

    # V·∫Ω s·ªë l∆∞·ª£ng m·∫´u ƒë∆∞·ª£c g√°n nh√£n
    ax3.plot(history['labeled_samples'], label='Labeled Samples')
    ax3.set_title('Number of Labeled Samples')
    ax3.set_xlabel('Iteration')
    ax3.set_ylabel('Number of Samples')
    ax3.legend()

    plt.tight_layout()
    return fig

# def run(X, y):
#     mlflow_input()

#     st.write("### Chia d·ªØ li·ªáu")
#     total_samples = X.shape[0]

#     # Thanh k√©o ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train
#     num_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train:",
#                             1000, total_samples, 10000)
#     st.session_state.total_samples = num_samples

#     # Thanh k√©o ch·ªçn t·ª∑ l·ªá Train/Test/Validation
#     test_size = st.slider("Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20) / 100
#     val_size = st.slider("Ch·ªçn % d·ªØ li·ªáu Validation", 0, 50, 10) / 100
#     train_size = 1.0 - test_size - val_size  # T·ª∑ l·ªá c√≤n l·∫°i cho train

#     if train_size <= 0:
#         st.error("T·ªïng t·ª∑ l·ªá Train + Validation + Test ph·∫£i nh·ªè h∆°n 100%!")
#         return None, None, None, None

#     # Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh theo y√™u c·∫ßu
#     X_selected, _, y_selected, _ = train_test_split(
#         X, y, train_size=num_samples/total_samples, stratify=y, random_state=42
#     )

#     # Chia train/test/val theo t·ª∑ l·ªá ƒë√£ ch·ªçn
#     X_temp, X_test, y_temp, y_test = train_test_split(
#         X_selected, y_selected, test_size=test_size/(1.0), stratify=y_selected, random_state=42
#     )
#     X_train, X_val, y_train, y_val = train_test_split(
#         X_temp, y_temp, test_size=val_size/(1.0 - test_size), stratify=y_temp, random_state=42
#     )

#     # L∆∞u v√†o session_state
#     st.session_state.X_train = X_train
#     st.session_state.X_val = X_val
#     st.session_state.X_test = X_test
#     st.session_state.y_train = y_train
#     st.session_state.y_val = y_val
#     st.session_state.y_test = y_test
#     st.session_state.test_size = X_test.shape[0]
#     st.session_state.val_size = X_val.shape[0]
#     st.session_state.train_size = X_train.shape[0]

#     # Chu·∫©n h√≥a d·ªØ li·ªáu
#     X_train = X_train.reshape(-1, 28 * 28) / 255.0
#     X_val = X_val.reshape(-1, 28 * 28) / 255.0
#     X_test = X_test.reshape(-1, 28 * 28) / 255.0

#     # Hi·ªÉn th·ªã b·∫£ng k√≠ch th∆∞·ªõc
#     table_size = pd.DataFrame({
#         'Dataset': ['Train', 'Validation', 'Test'],
#         'K√≠ch th∆∞·ªõc (%)': [train_size*100, val_size*100, test_size*100],
#         'S·ªë l∆∞·ª£ng m·∫´u': [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
#     })
#     st.write(table_size)

#     st.write("### Tham s·ªë hu·∫•n luy·ªán")

#     col1, col2 = st.columns(2)

#     with col1:
#         percentage = st.slider("T·ª∑ l·ªá d·ªØ li·ªáu labeled ban ƒë·∫ßu (%)",
#                                min_value=0.1, max_value=10.0, value=1.0) / 100
#         threshold = st.slider("Ng∆∞·ª°ng confidence",
#                               min_value=0.5, max_value=0.99, value=0.90, step=0.01)
#         max_iterations = st.number_input("S·ªë v√≤ng l·∫∑p t·ªëi ƒëa",
#                                          min_value=1, max_value=20, value=5)

#     with col2:
#         hidden1_size = st.number_input("K√≠ch th∆∞·ªõc l·ªõp ·∫©n 1",
#                                        min_value=32, max_value=512, value=128, step=32)
#         hidden2_size = st.number_input("K√≠ch th∆∞·ªõc l·ªõp ·∫©n 2",
#                                        min_value=32, max_value=512, value=64, step=32)

#         epochs = st.number_input("S·ªë epochs m·ªói iteration",
#                                  min_value=1, max_value=50, value=10)

#     dropout_rate = 0.2
#     batch_size = 32

#     # ƒê·∫∑t t√™n run
#     run_name = st.text_input("ƒê·∫∑t t√™n Run:", "")
#     timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
#     if not run_name.strip():
#         run_name = f"MNIST_Train_Process_{timestamp.replace(' ', '_').replace(':', '-')}"
#     else:
#         run_name = f"{run_name}_{timestamp.replace(' ', '_').replace(':', '-')}"
#     st.session_state["run_name"] = run_name

#     # N√∫t ch·∫°y
#     if st.button("Ch·∫°y Pseudo Labeling"):
#         # L·∫•y d·ªØ li·ªáu labeled ban ƒë·∫ßu t·ª´ t·∫≠p train
#         X_labeled, y_labeled = get_initial_labeled_data(
#             X_train, y_train, percentage)
#         X_unlabeled = np.delete(X_train, np.where(
#             np.isin(X_train, X_labeled).all(axis=1))[0], axis=0)

#         # T·∫°o model
#         input_shape = (28 * 28,)  # ƒê·∫£m b·∫£o input shape ph√π h·ª£p sau reshape
#         num_classes = len(np.unique(y))
#         model = create_model(input_shape, num_classes,
#                              hidden1_size, hidden2_size, dropout_rate)

#         # B·∫Øt ƒë·∫ßu MLflow run
#         run_name = st.session_state.get(
#             "run_name", f"MNIST_Train_Process_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}")
#         with mlflow.start_run(run_name=run_name):
#             # Log tham s·ªë
#             mlflow.log_param("num_samples", num_samples)
#             mlflow.log_param("train_size", train_size)
#             mlflow.log_param("val_size", val_size)
#             mlflow.log_param("test_size", test_size)
#             mlflow.log_param("percentage_labeled", percentage)
#             mlflow.log_param("threshold", threshold)
#             mlflow.log_param("max_iterations", max_iterations)
#             mlflow.log_param("hidden1_size", hidden1_size)
#             mlflow.log_param("hidden2_size", hidden2_size)
#             mlflow.log_param("dropout_rate", dropout_rate)
#             mlflow.log_param("epochs_per_iteration", epochs)
#             mlflow.log_param("batch_size", batch_size)

#             # L∆∞u l·ªãch s·ª≠
#             history = {'train_acc': [], 'val_acc': [], 'test_acc': [],
#                        'train_loss': [], 'val_loss': [], 'test_loss': [],
#                        'labeled_samples': [len(X_labeled)]}

#             for iteration in stqdm(range(max_iterations), desc="Training Progress"):
#                 st.write(f"\nIteration {iteration + 1}/{max_iterations}")

#                 # Hu·∫•n luy·ªán
#                 model.fit(X_labeled, y_labeled,
#                           epochs=epochs,
#                           batch_size=batch_size,
#                           validation_data=(X_val, y_val),
#                           verbose=1)

#                 # ƒê√°nh gi√°
#                 train_loss, train_acc = model.evaluate(
#                     X_labeled, y_labeled, verbose=0)
#                 val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)
#                 test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)

#                 history['train_acc'].append(train_acc)
#                 history['val_acc'].append(val_acc)
#                 history['test_acc'].append(test_acc)
#                 history['train_loss'].append(train_loss)
#                 history['val_loss'].append(val_loss)
#                 history['test_loss'].append(test_loss)

#                 # Log metrics cho m·ªói iteration
#                 mlflow.log_metric("train_accuracy", train_acc, step=iteration)
#                 mlflow.log_metric("val_accuracy", val_acc, step=iteration)
#                 mlflow.log_metric("test_accuracy", test_acc, step=iteration)
#                 mlflow.log_metric("train_loss", train_loss, step=iteration)
#                 mlflow.log_metric("val_loss", val_loss, step=iteration)
#                 mlflow.log_metric("test_loss", test_loss, step=iteration)
#                 mlflow.log_metric("labeled_samples", len(
#                     X_labeled), step=iteration)

#                 st.write(f"Train accuracy: {train_acc:.4f}")
#                 st.write(f"Validation accuracy: {val_acc:.4f}")
#                 st.write(f"Test accuracy: {test_acc:.4f}")

#                 if len(X_unlabeled) == 0:
#                     st.write("ƒê√£ g√°n nh√£n h·∫øt d·ªØ li·ªáu!")
#                     break

#                 # D·ª± ƒëo√°n tr√™n t·∫≠p unlabeled
#                 predictions = model.predict(X_unlabeled)
#                 confidence_scores = np.max(predictions, axis=1)
#                 pseudo_labels = np.argmax(predictions, axis=1)

#                 # Ch·ªçn m·∫´u v∆∞·ª£t ng∆∞·ª°ng
#                 confident_mask = confidence_scores >= threshold
#                 X_confident = X_unlabeled[confident_mask]
#                 y_confident = pseudo_labels[confident_mask]

#                 if len(X_confident) == 0:
#                     st.write("Kh√¥ng c√≤n m·∫´u n√†o v∆∞·ª£t ng∆∞·ª°ng confidence!")
#                     break

#                 # C·∫≠p nh·∫≠t t·∫≠p d·ªØ li·ªáu
#                 X_labeled = np.concatenate([X_labeled, X_confident])
#                 y_labeled = np.concatenate([y_labeled, y_confident])
#                 X_unlabeled = X_unlabeled[~confident_mask]

#                 history['labeled_samples'].append(len(X_labeled))

#                 st.write(f"S·ªë m·∫´u ƒë∆∞·ª£c g√°n nh√£n: {len(X_confident)}")
#                 st.write(f"S·ªë m·∫´u unlabeled c√≤n l·∫°i: {len(X_unlabeled)}")

#             # Log model cu·ªëi c√πng
#             mlflow.keras.log_model(model, "model")

#             if "models" not in st.session_state:
#                 st.session_state["models"] = []

#             model_name = "mnist_pseudo_label"
#             count = 1
#             new_model_name = model_name
#             while any(m["name"] == new_model_name for m in st.session_state["models"]):
#                 new_model_name = f"{model_name}_{count}"
#                 count += 1

#             st.session_state["models"].append(
#                 {"name": new_model_name, "model": model})
#             st.write(
#                 f"**M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v·ªõi t√™n:** `{new_model_name}`")

#             st.success(f"‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
#             st.write(
#                 f"Train accuracy cu·ªëi c√πng: {history['train_acc'][-1]:.4f}")
#             st.write(
#                 f"Validation accuracy cu·ªëi c√πng: {history['val_acc'][-1]:.4f}")
#             st.write(
#                 f"Test accuracy cu·ªëi c√πng: {history['test_acc'][-1]:.4f}")
#             st.write(
#                 f"Train loss cu·ªëi c√πng: {history['train_loss'][-1]:.4f}")
#             st.write(
#                 f"Validation loss cu·ªëi c√πng: {history['val_loss'][-1]:.4f}")
#             st.write(
#                 f"Test loss cu·ªëi c√πng: {history['test_loss'][-1]:.4f}")
#             st.success(
#                 f"‚úÖ Log d·ªØ li·ªáu **{st.session_state['run_name']}** th√†nh c√¥ng! üöÄ")

#             st.write("---")
#             # Visualize k·∫øt qu·∫£
#             with st.spinner("ƒêang tr·ª±c quan h√≥a k·∫øt qu·∫£ hu·∫•n luy·ªán ..."):
#                 st.subheader("Bi·ªÉu ƒë·ªì k·∫øt qu·∫£")
#                 fig = visualize_results(history)
#                 fig.savefig("results_plot.png")
#                 mlflow.log_artifact("results_plot.png")
#                 st.pyplot(fig)


def run(X, y):
    mlflow_input()

    st.write("### Chia d·ªØ li·ªáu")
    total_samples = X.shape[0]

    # Thanh k√©o ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train
    num_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train:",
                            1000, total_samples, 10000)
    num_samples = num_samples - 10
    st.session_state.total_samples = num_samples

    # Thanh k√©o ch·ªçn t·ª∑ l·ªá Train/Test/Validation
    test_size = st.slider("Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20)
    val_size = st.slider("Ch·ªçn % d·ªØ li·ªáu Validation", 0, 50, 10)
    train_size = 100 - test_size

    if train_size <= 0:
        st.error("T·ªïng t·ª∑ l·ªá Train + Validation + Test ph·∫£i nh·ªè h∆°n 100%!")
        return None, None, None, None

    # Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh theo y√™u c·∫ßu

    X_selected, _, y_selected, _ = train_test_split(
        X, y, train_size=num_samples, stratify=y, random_state=42)

    X_train_full, X_test, y_train_full, y_test = train_test_split(
        X_selected, y_selected, test_size=test_size/100, stratify=y_selected, random_state=42)

    X_train, X_val, y_train, y_val = train_test_split(
        X_train_full, y_train_full, test_size=val_size / (100 - test_size), stratify=y_train_full, random_state=42)

    # L∆∞u v√†o session_state
    st.session_state.X_train = X_train
    st.session_state.X_val = X_val
    st.session_state.X_test = X_test
    st.session_state.y_train = y_train
    st.session_state.y_val = y_val
    st.session_state.y_test = y_test
    st.session_state.test_size = X_test.shape[0]
    st.session_state.val_size = X_val.shape[0]
    st.session_state.train_size = X_train.shape[0]

    # Chu·∫©n h√≥a d·ªØ li·ªáu
    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_val = X_val.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0

    # Hi·ªÉn th·ªã b·∫£ng k√≠ch th∆∞·ªõc
    table_size = pd.DataFrame({
        'Dataset': ['Train', 'Validation', 'Test'],
        'K√≠ch th∆∞·ªõc (%)': [train_size*100, val_size*100, test_size*100],
        'S·ªë l∆∞·ª£ng m·∫´u': [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
    })
    st.write(table_size)

    st.write("### Tham s·ªë hu·∫•n luy·ªán")

    col1, col2 = st.columns(2)

    with col1:
        percentage = st.slider("T·ª∑ l·ªá d·ªØ li·ªáu labeled ban ƒë·∫ßu (%)",
                               min_value=0.1, max_value=10.0, value=0.1) / 100
        threshold = st.slider("Ng∆∞·ª°ng confidence",
                              min_value=0.5, max_value=0.99, value=0.95, step=0.01)
        max_iterations = st.number_input("S·ªë v√≤ng l·∫∑p t·ªëi ƒëa",
                                         min_value=1, max_value=20, value=5)

        learning_rate = st.number_input("T·ªëc ƒë·ªô h·ªçc",
                                        min_value=0.001, max_value=1.0, value=0.01)
        epochs = st.number_input("S·ªë epochs m·ªói iteration",
                                 min_value=1, max_value=50, value=10)

    with col2:
        hidden1_size = st.number_input("K√≠ch th∆∞·ªõc l·ªõp ·∫©n 1",
                                       min_value=32, max_value=512, value=128, step=32)
        hidden2_size = st.number_input("K√≠ch th∆∞·ªõc l·ªõp ·∫©n 2",
                                       min_value=32, max_value=512, value=64, step=32)

        activ_hd_1 = st.selectbox("H√†m k√≠ch ho·∫°t l·ªõp ·∫©n 1:", [
                                  "relu", "sigmoid", "tanh"])

        activ_hd_2 = st.selectbox("H√†m k√≠ch ho·∫°t l·ªõp ·∫©n 2:", [
                                  "relu", "sigmoid", "tanh"])

    dropout_rate = 0.2
    batch_size = 32

    # ƒê·∫∑t t√™n run
    run_name = st.text_input("ƒê·∫∑t t√™n Run:", "")
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    if not run_name.strip():
        run_name = f"MNIST_Train_Process_{timestamp.replace(' ', '_').replace(':', '-')}"
    else:
        run_name = f"{run_name}_{timestamp.replace(' ', '_').replace(':', '-')}"
    st.session_state["run_name"] = run_name
    X_labeled, y_labeled = get_initial_labeled_data(
        X_train, y_train, percentage)
    X_unlabeled = np.delete(X_train, np.where(
        np.isin(X_train, X_labeled).all(axis=1))[0], axis=0)

    # T·∫°o model
    input_shape = (28 * 28,)
    num_classes = len(np.unique(y))
    # N√∫t ch·∫°y
    if st.button("Ch·∫°y Pseudo Labeling"):
        with st.spinner("ƒêang hu·∫•n luy·ªán model v√† log v·ªõi MLflow..."):
            # Callback ƒë·ªÉ c·∫≠p nh·∫≠t thanh tr·∫°ng th√°i trong m·ªói v√≤ng
            status_text = st.empty()
            progress_bar = st.progress(0)

            class ProgressCallback(tf.keras.callbacks.Callback):
                def on_epoch_end(self, epoch, logs=None):
                    progress = ((iteration * epochs) + (epoch + 1)
                                ) / (max_iterations * epochs)
                    progress_bar.progress(min(int(progress * 100), 100))
                    status_text.text(
                        f"Ti·∫øn tr√¨nh hu·∫•n luy·ªán: {int(progress * 100)}%")
            model = create_model(input_shape, num_classes, hidden1_size, hidden2_size,
                                 dropout_rate, activ_hd_1, activ_hd_2, learning_rate)
            # B·∫Øt ƒë·∫ßu MLflow run
            with mlflow.start_run(run_name=run_name):
                # Log tham s·ªë
                mlflow.log_param("num_samples", num_samples)
                mlflow.log_param("train_size", train_size)
                mlflow.log_param("val_size", val_size)
                mlflow.log_param("test_size", test_size)
                mlflow.log_param("percentage_labeled", percentage)
                mlflow.log_param("threshold", threshold)
                mlflow.log_param("max_iterations", max_iterations)
                mlflow.log_param("hidden1_size", hidden1_size)
                mlflow.log_param("hidden1_method", activ_hd_1)
                mlflow.log_param("hidden2_size", hidden2_size)
                mlflow.log_param("hidden2_method", activ_hd_2)
                mlflow.log_param("dropout_rate", dropout_rate)
                mlflow.log_param("epochs_per_iteration", epochs)
                mlflow.log_param("batch_size", batch_size)
                mlflow.log_param("learning_rate", learning_rate)

            # L∆∞u l·ªãch s·ª≠
            history = {'train_acc': [], 'val_acc': [], 'test_acc': [],
                       'train_loss': [], 'val_loss': [], 'test_loss': [],
                       'labeled_samples': [len(X_labeled)]}

            st.write(
                f"Tr∆∞·ªõc hu·∫•n luy·ªán: X_labeled = {len(X_labeled)}, X_unlabeled = {len(X_unlabeled)}")

            # T·∫°o thanh ti·∫øn tr√¨nh
            progress_bar = st.progress(0)

            for iteration in range(max_iterations):
                # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh
                progress = (iteration + 1) / max_iterations
                progress_bar.progress(progress)

                st.write(f"\nIteration {iteration + 1}/{max_iterations}")

                # Hu·∫•n luy·ªán
                model.fit(X_labeled, y_labeled,
                          epochs=epochs,
                          batch_size=batch_size,
                          validation_data=(X_val, y_val),
                          verbose=0,
                          callbacks=[ProgressCallback()])

                # ƒê√°nh gi√°
                train_loss, train_acc = model.evaluate(
                    X_labeled, y_labeled, verbose=0)
                val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)
                test_loss, test_acc = model.evaluate(
                    X_test, y_test, verbose=0)

                history['train_acc'].append(train_acc)
                history['val_acc'].append(val_acc)
                history['test_acc'].append(test_acc)

                # Log metrics cho m·ªói iteration
                mlflow.log_metric(f"train_accuracy_{iteration+1}",
                                  train_acc, step=iteration)
                mlflow.log_metric("val_accuracy", val_acc, step=iteration)
                mlflow.log_metric(
                    f"test_accuracy_{iteration+1}", test_acc, step=iteration)
                mlflow.log_metric(
                    f"train_loss_{iteration+1}", train_loss, step=iteration)
                mlflow.log_metric(
                    f"val_loss_{iteration+1}", val_loss, step=iteration)
                mlflow.log_metric(
                    f"test_loss_{iteration+1}", test_loss, step=iteration)
                mlflow.log_metric(f"labeled_samples_{iteration+1}", len(
                    X_labeled), step=iteration)

                st.write(f"Train accuracy: {train_acc:.4f}")
                st.write(f"Validation accuracy: {val_acc:.4f}")
                st.write(f"Test accuracy: {test_acc:.4f}")

                if len(X_unlabeled) == 0:
                    st.write("ƒê√£ g√°n nh√£n h·∫øt d·ªØ li·ªáu!")
                    break

                # D·ª± ƒëo√°n tr√™n t·∫≠p unlabeled
                predictions = model.predict(X_unlabeled)
                confidence_scores = np.max(predictions, axis=1)
                pseudo_labels = np.argmax(predictions, axis=1)

                # Ch·ªçn m·∫´u v∆∞·ª£t ng∆∞·ª°ng
                confident_mask = confidence_scores >= threshold
                X_confident = X_unlabeled[confident_mask]
                y_confident = pseudo_labels[confident_mask]

                if len(X_confident) == 0:
                    st.write("Kh√¥ng c√≤n m·∫´u n√†o v∆∞·ª£t ng∆∞·ª°ng confidence!")
                    break

                # C·∫≠p nh·∫≠t t·∫≠p d·ªØ li·ªáu
                X_labeled = np.concatenate([X_labeled, X_confident])
                y_labeled = np.concatenate([y_labeled, y_confident])
                X_unlabeled = X_unlabeled[~confident_mask]

                history['labeled_samples'].append(len(X_labeled))

                st.write(f"S·ªë m·∫´u ƒë∆∞·ª£c g√°n nh√£n: {len(X_confident)}")
                st.write(f"S·ªë m·∫´u unlabeled c√≤n l·∫°i: {len(X_unlabeled)}")

            # Log model cu·ªëi c√πng
            mlflow.keras.log_model(model, "model")

            if "models" not in st.session_state:
                st.session_state["models"] = []

            model_name = "mnist_pseudo_label"
            count = 1
            new_model_name = model_name
            while any(m["name"] == new_model_name for m in st.session_state["models"]):
                new_model_name = f"{model_name}_{count}"
                count += 1

            st.session_state["models"].append(
                {"name": new_model_name, "model": model})
            st.write(
                f"**M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v·ªõi t√™n:** `{new_model_name}`")

            st.success(f"‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
            st.write(
                f"Train accuracy cu·ªëi c√πng: {history['train_acc'][-1]:.4f}")
            st.write(
                f"Validation accuracy cu·ªëi c√πng: {history['val_acc'][-1]:.4f}")
            st.write(
                f"Test accuracy cu·ªëi c√πng: {history['test_acc'][-1]:.4f}")
            st.write(
                f"Train loss cu·ªëi c√πng: {history['train_loss'][-1]:.4f}")
            st.write(
                f"Validation loss cu·ªëi c√πng: {history['val_loss'][-1]:.4f}")
            st.write(
                f"Test loss cu·ªëi c√πng: {history['test_loss'][-1]:.4f}")
            st.success(
                f"‚úÖ Log d·ªØ li·ªáu **{st.session_state['run_name']}** th√†nh c√¥ng! üöÄ")

        # Visualize k·∫øt qu·∫£
        with st.spinner("ƒêang tr·ª±c quan h√≥a k·∫øt qu·∫£ hu·∫•n luy·ªán ..."):
            st.subheader("Bi·ªÉu ƒë·ªì k·∫øt qu·∫£")
            fig = visualize_results(history)
            fig.savefig("results_plot.png")
            mlflow.log_artifact("results_plot.png")
            st.pyplot(fig)
