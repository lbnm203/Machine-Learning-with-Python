import streamlit as st
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.model_selection import train_test_split
import os
import mlflow
from mlflow.tracking import MlflowClient
import matplotlib.pyplot as plt
import numpy as np
import time


def input_mlflow():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/lbnm203/Machine_Learning_UI.mlflow/"
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    os.environ["MLFLOW_TRACKING_USERNAME"] = "lbnm203"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "0902d781e6c2b4adcd3cbf60e0f288a8085c5aab"
    mlflow.set_experiment("MNIST_PCA_t-SNE")


@st.cache_data
def fit_tnse(X, n_components, perplexity, learning_rate, n_iter, metric):
    tsne = TSNE(n_components=n_components, perplexity=perplexity, learning_rate=learning_rate,
                n_iter=n_iter, metric=metric, random_state=42)
    X_train_tsne = tsne.fit_transform(X)
    return X_train_tsne, tsne


def train_pca(X, y):
    total_samples = X.shape[0]

    # Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train
    num_samples = st.slider(
        'Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh cho ph·∫ßn hu·∫•n luy·ªán', 1000, total_samples, 70000)

    # Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh theo y√™u c·∫ßu
    X_selected, y_selected = X[:num_samples], y[:num_samples]

    # Ch·ªçn t·ª∑ l·ªá train v√† test
    test_size = st.slider('Test size', 0.0, 1.0, 0.3)

    # Chia train/test theo t·ª∑ l·ªá ƒë√£ ch·ªçn
    X_train, X_test, y_train, y_test = train_test_split(
        X_selected, y_selected, test_size=test_size, random_state=42)

    # Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng m·∫´u d∆∞·ªõi d·∫°ng b·∫£ng
    st.write("### S·ªë l∆∞·ª£ng m·∫´u")
    data = {
        "T·∫≠p": ["Train", "Test"],
        "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_test.shape[0]],
        "T·ª∑ l·ªá (%)": [int((1 - test_size) * 100), int(test_size * 100)]
    }
    st.table(data)

    if "X_train" not in st.session_state or "X_test" not in st.session_state or "y_train" not in st.session_state or "y_test" not in st.session_state:
        st.session_state["X_train"] = X_train
        st.session_state["X_test"] = X_test
        st.session_state["y_train"] = y_train
        st.session_state["y_test"] = y_test

    # Chu·∫©n h√≥a d·ªØ li·ªáu
    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0

    input_mlflow()

    run_name = st.text_input("Nh·∫≠p t√™n Run:", "Default Run")
    if not run_name:
        run_name = "default_run"
    st.session_state["run_name"] = run_name

    dim_reduction_method = st.selectbox(
        "**Ch·ªçn ph∆∞∆°ng ph√°p r√∫t g·ªçn chi·ªÅu d·ªØ li·ªáu:**", ["PCA", "t-SNE"])
    if dim_reduction_method == "PCA":
        col1, col2 = st.columns(2)
        with col1:
            # Tham s·ªë c·ªßa PCA
            n_components = st.slider("**S·ªë th√†nh ph·∫ßn ch√≠nh (n_components):**",
                                     min_value=2, max_value=min(X_train.shape[1], 20),
                                     value=5,
                                     help="""
S·ªë l∆∞·ª£ng chi·ªÅu (`n_components`) mu·ªën gi·ªØ l·∫°i sau khi gi·∫£m chi·ªÅu b·∫±ng PCA. 
- Gi√° tr·ªã nh·ªè h∆°n (v√≠ d·ª•: 2-5) ph√π h·ª£p cho tr·ª±c quan h√≥a, nh∆∞ng c√≥ th·ªÉ m·∫•t th√¥ng tin. 
- Gi√° tr·ªã l·ªõn h∆°n gi·ªØ l·∫°i nhi·ªÅu th√¥ng tin h∆°n nh∆∞ng l√†m tƒÉng ƒë·ªô ph·ª©c t·∫°p t√≠nh to√°n
""")
            svd_solver = st.selectbox("**Thu·∫≠t to√°n SVD:**",
                                      ["auto", "full", "arpack", "randomized"],
                                      help="""
Thu·∫≠t to√°n SVD ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t√≠nh to√°n PCA:
- `auto`: Ch·ªçn thu·∫≠t to√°n t·ª± ƒë·ªông d·ª±a tr√™n k√≠ch th∆∞·ªõc d·ªØ li·ªáu.
- `full`: T√≠nh to√†n b·ªô ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai, ph√π h·ª£p v·ªõi d·ªØ li·ªáu nh·ªè.
- `arpack`: D√πng cho d·ªØ li·ªáu l·ªõn, t·ªëi ∆∞u h√≥a b·ªô nh·ªõ nh∆∞ng ch·∫≠m h∆°n.
- `randomized`: TƒÉng t·ªëc tr√™n d·ªØ li·ªáu l·ªõn, nh∆∞ng c√≥ th·ªÉ √≠t ch√≠nh x√°c h∆°n v·ªõi d·ªØ li·ªáu nh·ªè.
                """)

            st.warning("""
- Th·ª© t·ª± ∆∞u ti√™n :
    - "auto" (M·∫∑c ƒë·ªãnh, ∆∞u ti√™n cao nh·∫•t):
        - L√Ω do: T·ª± ƒë·ªông ch·ªçn thu·∫≠t to√°n t·ªët nh·∫•t d·ª±a tr√™n d·ªØ li·ªáu, kh√¥ng c·∫ßn can thi·ªáp th·ªß c√¥ng, ph√π h·ª£p v·ªõi h·∫ßu h·∫øt c√°c tr∆∞·ªùng h·ª£p.
    - "randomized" (∆Øu ti√™n cao, ƒë·∫∑c bi·ªát v·ªõi d·ªØ li·ªáu l·ªõn):
        - L√Ω do: Nhanh nh·∫•t tr√™n d·ªØ li·ªáu l·ªõn, ph√π h·ª£p v·ªõi MNIST ho·∫∑c c√°c t·∫≠p d·ªØ li·ªáu c√≥ h√†ng ng√†n m·∫´u v√† ƒë·∫∑c tr∆∞ng.
    - "arpack" (∆Øu ti√™n trung b√¨nh, ph√π h·ª£p v·ªõi d·ªØ li·ªáu l·ªõn nh∆∞ng c·∫ßn ki·ªÉm so√°t b·ªô nh·ªõ):
        - L√Ω do: T·ªëi ∆∞u h√≥a b·ªô nh·ªõ, nh∆∞ng ch·∫≠m h∆°n "randomized" v√† ch·ªâ h·ªØu √≠ch khi n_features >> n_samples.
    - "full" (∆Øu ti√™n th·∫•p nh·∫•t, ch·ªâ d√πng v·ªõi d·ªØ li·ªáu nh·ªè):
        - L√Ω do: Ch√≠nh x√°c nh·∫•t nh∆∞ng t·ªën b·ªô nh·ªõ v√† th·ªùi gian, kh√¥ng ph√π h·ª£p v·ªõi d·ªØ li·ªáu l·ªõn.
""")

        if st.button("üöÄ Ch·∫°y PCA"):
            progress_bar = st.progress(0)
            for i in range(1, 101):
                progress_bar.progress(i)
                time.sleep(0.01)
            st.write("Qu√° tr√¨nh hu·∫•n luy·ªán ƒë√£ ho√†n th√†nh!")
            with mlflow.start_run(run_name=st.session_state["run_name"]) as run:
                mlflow.set_tag("mlflow.runName", st.session_state["run_name"])
                # √Åp d·ª•ng PCA
                pca = PCA(n_components=n_components,
                          svd_solver=svd_solver, random_state=42)
                X_train_pca = pca.fit_transform(X_train)

                progress_bar = st.progress(0)
                for i in range(1, 101):
                    progress_bar.progress(i)
                    time.sleep(0.01)
                st.write("Qu√° tr√¨nh hu·∫•n luy·ªán ƒë√£ ho√†n th√†nh!")

                st.session_state.X_train_pca = X_train_pca
                st.session_state.explained_variance_ratio_ = pca.explained_variance_ratio_
                explained_variance = np.sum(pca.explained_variance_ratio_)

                # Log tham s·ªë v√†o MLflow
                mlflow.log_param("algorithm", dim_reduction_method)
                mlflow.log_param("n_components", n_components)
                mlflow.log_param("svd_solver", svd_solver)
                mlflow.log_param("X_train_pca", X_train_pca)
                mlflow.log_metric("explained_variance", explained_variance)

                # L∆∞u PCA data
                np.save("X_train_pca.npy", X_train_pca)
                mlflow.log_artifact("X_train_pca.npy")

                with col2:
                    st.subheader(
                        f"H√¨nh ·∫£nh k·∫øt qu·∫£: Gi·∫£m xu·ªëng c√≤n {n_components} chi·ªÅu d·ªØ li·ªáu s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p {dim_reduction_method}")
                    fig2, ax = plt.subplots()
                    scatter = ax.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train[:X_train_pca.shape[0]].astype(
                        int), cmap='tab10', alpha=0.6)
                    legend = ax.legend(
                        *scatter.legend_elements(), title="Digits")
                    ax.add_artist(legend)
                    st.pyplot(fig2)
                    fig2.savefig("pca_result.png")
                    mlflow.log_artifact("pca_result.png")

                st.write("---")
                # Tr·ª±c quan h√≥a ph∆∞∆°ng sai gi·∫£i th√≠ch
                st.subheader(
                    "K·∫øt qu·∫£ tr·ª±c quan h√≥a", help="""
- Trong PCA:
    - T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch l√† ph·∫ßn trƒÉm ph∆∞∆°ng sai m√† m·ªói th√†nh ph·∫ßn ch√≠nh ƒë√≥ng g√≥p v√†o t·ªïng ph∆∞∆°ng sai 
    c·ªßa d·ªØ li·ªáu g·ªëc.
        - √ù nghƒ©a: T·ª∑ l·ªá n√†y cho b·∫°n bi·∫øt m·ªói th√†nh ph·∫ßn ch√≠nh ƒë√≥ng g√≥p bao nhi√™u ph·∫ßn trƒÉm v√†o t·ªïng th√¥ng tin c·ªßa d·ªØ li·ªáu, gi√∫p d·ªÖ d√†ng ƒë√°nh gi√° xem 
        bao nhi√™u th√†nh ph·∫ßn c·∫ßn thi·∫øt ƒë·ªÉ gi·ªØ l·∫°i m·ªôt l∆∞·ª£ng th√¥ng tin nh·∫•t ƒë·ªãnh (v√≠ d·ª•: 90% ho·∫∑c 95%). 
""")

            col1, col2 = st.columns([2, 1])
            with col1:
                fig, ax = plt.subplots(1, 1, figsize=(6, 4))

                # # Bi·ªÉu ƒë·ªì c·ªôt cho explained_variance_
                # ax.bar(range(1, len(pca.explained_variance_) + 1),
                #         pca.explained_variance_)
                # ax.set_title("Ph∆∞∆°ng sai gi·∫£i th√≠ch")
                # ax.set_xlabel("Th√†nh ph·∫ßn ch√≠nh")
                # ax.set_ylabel("Ph∆∞∆°ng sai")

                # Bi·ªÉu ƒë·ªì c·ªôt cho explained_variance_ratio_
                ax.bar(
                    range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)
                ax.set_title("T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch")
                ax.set_xlabel("Th√†nh ph·∫ßn ch√≠nh")
                ax.set_ylabel("T·ª∑ l·ªá")

                st.pyplot(fig)

            with col2:
                explained_var_r = pca.explained_variance_ratio_
                explanation_data = {
                    "Th√†nh ph·∫ßn ch√≠nh": [f"Th√†nh ph·∫ßn {i+1}" for i in range(len(explained_var_r))],
                    "T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch (%)": [f"{var*100:.2f}%" for var in explained_var_r]
                }
                st.table(explanation_data)

            st.success(
                f"T·ªïng s·ªë ph∆∞∆°ng sai gi·∫£ th√≠ch: {sum(pca.explained_variance_ratio_)}")

            st.success(
                f"Log tham s·ªë cho **Train_{st.session_state['run_name']}**!")
            st.markdown(
                f"### üîó [Truy c·∫≠p MLflow DAGsHub]({st.session_state['mlflow_url']})")

            mlflow.end_run()

    elif dim_reduction_method == "t-SNE":
        col1, col2 = st.columns(2)
        with col1:
            # Tham s·ªë c·ªßa t-SNE
            n_components = st.selectbox("**S·ªë chi·ªÅu ƒë·∫ßu ra:**", [2, 3],
                                        help="""S·ªë chi·ªÅu mu·ªën gi·∫£m xu·ªëng b·∫±ng t-SNE. Th∆∞·ªùng ch·ªâ c·∫ßn 2 chi·ªÅu ƒë·ªÉ 
                                        tr·ª±c quan h√≥a scatter plot (ph√π h·ª£p nh·∫•t v·ªõi MNIST). Gi√° tr·ªã 3 c√≥ th·ªÉ 
                                        h·ªØu √≠ch cho ph√¢n t√≠ch ph·ª©c t·∫°p h∆°n, nh∆∞ng tƒÉng th·ªùi gian t√≠nh to√°n v√† 
                                        kh√≥ tr·ª±c quan h√≥a h∆°n.""")
            perplexity = st.slider(
                "**Perplexity:**", min_value=5, max_value=50, value=30, help="""
Tham s·ªë perplexity ki·ªÉm so√°t s·ªë l∆∞·ª£ng ƒëi·ªÉm l√¢n c·∫≠n ƒë∆∞·ª£c xem x√©t trong qu√° tr√¨nh gi·∫£m chi·ªÅu. 
Gi√° tr·ªã nh·ªè (5-15) ph√π h·ª£p v·ªõi d·ªØ li·ªáu nh·ªè, gi√° tr·ªã l·ªõn (30-50) ph√π h·ª£p v·ªõi d·ªØ li·ªáu l·ªõn h∆°n. 
Gi√° tr·ªã qu√° l·ªõn ho·∫∑c qu√° nh·ªè c√≥ th·ªÉ l√†m m·∫•t c·∫•u tr√∫c d·ªØ li·ªáu.
""")
            learning_rate = st.slider(
                "**Learning rate:**", min_value=0.001, max_value=0.5, value=0.1, help="""
T·ªëc ƒë·ªô h·ªçc (learning rate) ƒëi·ªÅu ch·ªânh b∆∞·ªõc di chuy·ªÉn c·ªßa thu·∫≠t to√°n t-SNE. Gi√° tr·ªã qu√° nh·ªè (0.001-0.01) 
c√≥ th·ªÉ l√†m ch·∫≠m qu√° tr√¨nh h·ªôi t·ª•, trong khi gi√° tr·ªã qu√° l·ªõn (0.1, 0.5) c√≥ th·ªÉ g√¢y m·∫•t ·ªïn ƒë·ªãnh. M·∫∑c ƒë·ªãnh 
0.01 th∆∞·ªùng ph√π h·ª£p v·ªõi nhi·ªÅu d·ªØ li·ªáu.
""")
            n_iter = st.slider("**S·ªë v√≤ng l·∫∑p t·ªëi ƒëa:**",
                               min_value=250, max_value=5000, value=1000, step=250, help="""
S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa cho t-SNE ƒë·ªÉ t·ªëi ∆∞u h√≥a. Gi√° tr·ªã nh·ªè (250-1000) gi·∫£m th·ªùi gian t√≠nh to√°n nh∆∞ng 
c√≥ th·ªÉ kh√¥ng h·ªôi t·ª• ƒë·∫ßy ƒë·ªß, trong khi gi√° tr·ªã l·ªõn (2000-5000) tƒÉng ƒë·ªô ch√≠nh x√°c nh∆∞ng k√©o d√†i th·ªùi gian. 
Ch·ªçn d·ª±a tr√™n k√≠ch th∆∞·ªõc d·ªØ li·ªáu v√† y√™u c·∫ßu t·ªëc ƒë·ªô.
""")
            metric = st.selectbox("**ƒê·ªô ƒëo kho·∫£ng c√°ch:**",
                                  ["euclidean", "cosine", "manhattan"], help="""
ƒê·ªô ƒëo kho·∫£ng c√°ch ƒë·ªÉ t√≠nh to√°n s·ª± t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c ƒëi·ªÉm trong t-SNE:
- `euclidean`: Kho·∫£ng c√°ch Euclid (m·∫∑c ƒë·ªãnh, ph√π h·ª£p cho d·ªØ li·ªáu s·ªë).
- `cosine`: Kho·∫£ng c√°ch Cosine, h·ªØu √≠ch cho d·ªØ li·ªáu vector h∆∞·ªõng.
- `manhattan`: Kho·∫£ng c√°ch Manhattan, ph√π h·ª£p v·ªõi d·ªØ li·ªáu c√≥ ph√¢n ph·ªëi ƒë·∫∑c bi·ªát.
""")

        if st.button("üöÄ Ch·∫°y t-SNE"):
            progress_bar = st.progress(0)
            for i in range(1, 101):
                progress_bar.progress(i)
                time.sleep(0.01)
            st.write("Qu√° tr√¨nh hu·∫•n luy·ªán ƒë√£ ho√†n th√†nh!")
            with mlflow.start_run(run_name=st.session_state["run_name"]) as run:
                mlflow.set_tag("mlflow.runName", st.session_state["run_name"])
                # # √Åp d·ª•ng t-SNE
                # tsne = TSNE(n_components=n_components, perplexity=perplexity, learning_rate=learning_rate,
                #             n_iter=n_iter, metric=metric, random_state=42)
                X_train_tsne, tsne = fit_tnse(
                    X_train, n_components, perplexity, learning_rate, n_iter, metric)

                # L∆∞u k·∫øt qu·∫£ t-SNE
                st.session_state.X_train_tsne = X_train_tsne

                try:
                    st.session_state.kl_divergence = tsne.kl_divergence_
                except AttributeError:
                    st.session_state.kl_divergence = "Kh√¥ng c√≥ th√¥ng tin v·ªÅ k1 divergence"
                mlflow.log_param("algorithm", "t-SNE")
                mlflow.log_param("n_components", n_components)
                mlflow.log_param("perplexity", perplexity)
                mlflow.log_param("learning_rate", learning_rate)
                mlflow.log_param("n_iter", n_iter)
                mlflow.log_param("metric", metric)
                mlflow.log_param("X_train_tsne", X_train_tsne)

                np.save("X_train_tsne.npy", X_train_tsne)
                mlflow.log_artifact("X_train_tsne.npy")

                with col2:
                    st.subheader(
                        f"H√¨nh ·∫£nh k·∫øt qu·∫£: Gi·∫£m xu·ªëng c√≤n {n_components} chi·ªÅu d·ªØ li·ªáu s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p {dim_reduction_method}")
                    fig2, ax = plt.subplots()
                    scatter = ax.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], c=y_train[:X_train_tsne.shape[0]].astype(
                        int), cmap='tab10', alpha=0.6)
                    legend = ax.legend(
                        *scatter.legend_elements(), title="Digits")
                    ax.add_artist(legend)
                    st.pyplot(fig2)
                    fig2.savefig("tnse_result.png")
                    mlflow.log_artifact("tnse_result.png")
            st.success(
                f"Log tham s·ªë cho **Train_{st.session_state['run_name']}**!")
            st.markdown(
                f"### üîó [Truy c·∫≠p MLflow DAGsHub]({st.session_state['mlflow_url']})")

            mlflow.end_run()
