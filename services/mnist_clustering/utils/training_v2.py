import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import streamlit as st
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score, adjusted_rand_score
import matplotlib.pyplot as plt
import os
import mlflow
import time
import datetime


def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/lbnm203/Machine_Learning_UI.mlflow"
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    os.environ["MLFLOW_TRACKING_USERNAME"] = "lbnm203"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "0902d781e6c2b4adcd3cbf60e0f288a8085c5aab"

    mlflow.set_experiment("MNIST_Clustering")


@st.cache_resource
def train_kmeans(X, n_clusters):
    # ƒê·∫£m b·∫£o X l√† 2D
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(X)
    return kmeans, labels


@st.cache_resource
def train_dbscan(X, eps, min_samples):
    dbscan = DBSCAN(eps=eps, min_samples=min_samples)
    labels = dbscan.fit_predict(X)
    return dbscan, labels


def plot_clusters(X, labels, method, params, run):
    # V√¨ kh√¥ng d√πng PCA, ta s·∫Ω v·∫Ω m·ªôt bi·ªÉu ƒë·ªì ƒë∆°n gi·∫£n h∆°n, v√≠ d·ª•: histogram
    fig, ax = plt.subplots(figsize=(10, 6))
    unique_labels = np.unique(labels)
    ax.hist(labels, bins=len(unique_labels), edgecolor='black')
    ax.set_title(f"{method} Cluster Distribution")
    ax.set_xlabel("Cluster Label")
    ax.set_ylabel("Number of Samples")
    st.pyplot(fig)

    plot_file = f"{method.lower()}_distribution.png"
    fig.savefig(plot_file)
    if run:
        mlflow.log_artifact(plot_file, artifact_path="visualizations")
    plt.close(fig)


def visualize_dbscan(X, labels, images):
    unique_labels = np.unique(labels)
    # ƒê·∫øm s·ªë c·ª•m, kh√¥ng t√≠nh noise
    n_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)
    n_noise = np.sum(labels == -1)

    # 1. Hi·ªÉn th·ªã l∆∞·ªõi h√¨nh ·∫£nh ƒë·∫°i di·ªán
    n_samples_per_cluster = 5
    fig, axes = plt.subplots(len(unique_labels), n_samples_per_cluster,
                             figsize=(n_samples_per_cluster*2, len(unique_labels)*2))
    for i, cluster in enumerate(unique_labels):
        cluster_indices = np.where(labels == cluster)[0]
        samples = np.random.choice(cluster_indices, min(
            n_samples_per_cluster, len(cluster_indices)), replace=False)
        for j, sample_idx in enumerate(samples):
            if len(unique_labels) == 1:
                ax = axes[j] if n_samples_per_cluster > 1 else axes
            else:
                ax = axes[i, j]
            ax.imshow(images[sample_idx], cmap='gray')
            ax.axis('off')
            if j == 0:
                ax.set_title(
                    f'{"Noise" if cluster == -1 else f"C·ª•m {cluster}"}')
    plt.suptitle(
        f"K·∫øt qu·∫£ DBSCAN: {n_clusters} c·ª•m, {n_noise} ƒëi·ªÉm noise", y=1.05)
    plt.tight_layout()

    # 2. Bi·ªÉu ƒë·ªì c·ªôt s·ªë l∆∞·ª£ng m·∫´u
    cluster_counts = pd.Series(labels).value_counts().sort_index()
    fig2, ax2 = plt.subplots(figsize=(8, 4))
    cluster_counts.plot(kind='bar', ax=ax2)
    ax2.set_title("S·ªë l∆∞·ª£ng m·∫´u trong m·ªói c·ª•m (bao g·ªìm noise)")
    ax2.set_xlabel("Nh√£n c·ª•m (-1 l√† noise)")
    ax2.set_ylabel("S·ªë l∆∞·ª£ng m·∫´u")
    plt.tight_layout()

    return fig, fig2


def compare_clusters_with_true_labels(X, y_true, labels_pred, method, n_samples_per_cluster=5):
    """
    So s√°nh nh√£n c·ª•m d·ª± ƒëo√°n v·ªõi nh√£n th·∫≠t v√† hi·ªÉn th·ªã ·∫£nh m·∫´u.
    X: D·ªØ li·ªáu g·ªëc (ch∆∞a reshape)
    y_true: Nh√£n th·∫≠t
    labels_pred: Nh√£n c·ª•m d·ª± ƒëo√°n
    method: T√™n m√¥ h√¨nh (KMeans ho·∫∑c DBSCAN)
    n_samples_per_cluster: S·ªë ·∫£nh m·∫´u hi·ªÉn th·ªã cho m·ªói c·ª•m
    """
    # Hi·ªÉn th·ªã ·∫£nh m·∫´u t·ª´ m·ªói c·ª•m (bao g·ªìm nhi·ªÖu n·∫øu c√≥)
    unique_labels = np.unique(labels_pred)
    st.write(f"### Hi·ªÉn th·ªã {n_samples_per_cluster} ·∫£nh m·∫´u t·ª´ m·ªói c·ª•m/nhi·ªÖu")

    for cluster in unique_labels:
        if cluster == -1 and method == "DBSCAN":
            st.write(f"#### Nhi·ªÖu (Cluster -1)")
        else:
            st.write(f"#### C·ª•m {cluster}")

        # L·∫•y ch·ªâ s·ªë c·ªßa c√°c m·∫´u trong c·ª•m n√†y
        cluster_indices = np.where(labels_pred == cluster)[0]
        if len(cluster_indices) == 0:
            st.write("Kh√¥ng c√≥ m·∫´u n√†o trong c·ª•m n√†y.")
            continue

        # Ch·ªçn ng·∫´u nhi√™n t·ªëi ƒëa n_samples_per_cluster m·∫´u
        sample_indices = np.random.choice(cluster_indices,
                                          min(n_samples_per_cluster,
                                              len(cluster_indices)),
                                          replace=False)

        # T·∫°o figure ƒë·ªÉ hi·ªÉn th·ªã ·∫£nh
        fig_kmeans, axes = plt.subplots(
            1, len(sample_indices), figsize=(2 * len(sample_indices), 2))
        if len(sample_indices) == 1:
            axes = [axes]  # ƒê·∫£m b·∫£o axes l√† iterable

        for idx, ax in zip(sample_indices, axes):
            # Gi·∫£ s·ª≠ X l√† ·∫£nh MNIST (28x28), c·∫ßn reshape l·∫°i t·ª´ flatten n·∫øu c·∫ßn
            img = X[idx].reshape(28, 28) if X[idx].size == 784 else X[idx]
            ax.imshow(img, cmap='gray')
            ax.axis('off')

            # Save the figure to a file only if within an active MLflow run
            if mlflow.active_run():
                plot_file = f"{method.lower()}_cluster_samples.png"
                fig_kmeans.savefig(plot_file)
                mlflow.log_artifact(plot_file, artifact_path="visualizations")

                # L∆∞u v√†o session_state
                if "cluster_fig" not in st.session_state:
                    st.session_state["cluster_fig"] = {}

                st.session_state["cluster_fig"]["KMeans"] = fig_kmeans

        st.pyplot(fig_kmeans)
        plt.close(fig_kmeans)


def train_process(X, y):
    st.write("Qu√° tr√¨nh hu·∫•n luy·ªán")

    total_samples = X.shape[0]

    num_samples = st.slider(
        'Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh cho ph·∫ßn hu·∫•n luy·ªán', 1000, total_samples, 10000)
    X_selected, y_selected = X[:num_samples], y[:num_samples]

    test_size = st.slider('Test size', 0.0, 1.0, 0.3)

    if st.button("Chia D·ªØ Li·ªáu"):
        with st.spinner("ƒêang t·∫£i v√† chia d·ªØ li·ªáu..."):
            start_time = time.time()
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y_selected, test_size=test_size, random_state=42)
            training_time = time.time() - start_time

            st.success(f"üëâ Chia D·ªØ Li·ªáu Th√†nh C√¥ng! - {training_time:.2f}s")

            st.write("### S·ªë l∆∞·ª£ng m·∫´u")
            data = {
                "T·∫≠p": ["Train", "Test"],
                "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_test.shape[0]],
                "T·ª∑ l·ªá (%)": [int((1 - test_size) * 100), int(test_size * 100)]
            }
            st.table(data)

            st.session_state['X_train'] = X_train
            st.session_state['X_test'] = X_test
            st.session_state['y_train'] = y_train
            st.session_state['y_test'] = y_test

    if "X_train" not in st.session_state:
        st.warning("‚ö†Ô∏è Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc khi train!")
        return

    X_train = st.session_state["X_train"]
    y_train = st.session_state["y_train"]

    # Chu·∫©n h√≥a d·ªØ li·ªáu
    X_train_norm = (X_train.reshape(-1, 28 * 28) / 255.0).astype(np.float32)
    st.session_state["X_train_norm"] = X_train_norm

    model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh:", ["KMeans", "DBSCAN"])

    mlflow_input()
    run_name = st.text_input("Enter Run Name:", "")
    if run_name.strip() == "" or run_name.strip() == " ":
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        run_name = f"MNIST_Clustering_{timestamp.replace(' ', '_').replace(':', '-')}"

    st.session_state["run_name"] = run_name

    if model_choice == "KMeans":
        n_clusters = st.slider("üî¢ Ch·ªçn s·ªë c·ª•m (K):", 2, 20, 10)
        # n_init = st.slider("üîÑ S·ªë l·∫ßn kh·ªüi t·∫°o:", 1, 20, 10)

        if st.button("Train KMeans"):
            with mlflow.start_run(run_name=run_name):
                with st.spinner("ƒêang hu·∫•n luy·ªán KMeans..."):
                    start_time = time.time()
                    model, labels = train_kmeans(
                        X_train_norm, n_clusters)
                    training_time = time.time() - start_time

                    # T√≠nh silhouette score
                    silhouette = silhouette_score(X_train_norm, labels)

                    # Log parameters v√† metrics v√†o MLflow
                    mlflow.log_param("model", "KMeans")
                    mlflow.log_param("Training Size", X_train.shape[0])
                    mlflow.log_param("n_clusters", n_clusters)
                    mlflow.log_metric("silhouette_score", silhouette)
                    mlflow.log_metric("training_time", training_time)

                    col1, col2, col3 = st.columns([1, 3, 1])
                    # V·∫Ω ph√¢n b·ªë c·ª•m
                    with col2:
                        plot_clusters(X_train_norm, labels, "KMeans",
                                      {"n_clusters": n_clusters}, True)
                    compare_clusters_with_true_labels(
                        X_train, y_train, labels, "KMeans")

                    st.success(
                        f"‚úÖ Hu·∫•n luy·ªán KMeans ho√†n t·∫•t! Th·ªùi gian: {training_time:.2f}s")
                    st.success(f"Silhouette Score: {silhouette:.4f}")

            model_name = model_choice.lower().replace(" ", "_")
            count = 1
            new_model_name = model_name
            while any(m["name"] == new_model_name for m in st.session_state["models"]):
                new_model_name = f"{model_name}_{count}"
                count += 1

            st.session_state["models"].append(
                {"name": new_model_name, "model": model})
            st.write(f"üîπ **M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v·ªõi t√™n:** `{new_model_name}`")

    elif model_choice == "DBSCAN":
        eps = st.slider("B√°n k√≠nh l√¢n c·∫≠n (epsilon):", 0.1, 10.0, 0.5)
        min_samples = st.slider("S·ªë ƒëi·ªÉm t·ªëi thi·ªÉu trong c·ª•m:", 2, 20, 5)

        if st.button("Train DBSCAN"):
            with mlflow.start_run(run_name=run_name):
                with st.spinner("ƒêang hu·∫•n luy·ªán DBSCAN..."):
                    start_time = time.time()
                    model, labels = train_dbscan(
                        X_train_norm, eps, min_samples)
                    training_time = time.time() - start_time

                    # ƒê·∫øm s·ªë c·ª•m (lo·∫°i b·ªè nhi·ªÖu -1)
                    n_clusters = len(set(labels) - {-1})
                    silhouette = silhouette_score(
                        X_train_norm, labels) if n_clusters > 1 else -1
                    ari = adjusted_rand_score(y_train, labels)
                    noise_ratio = np.sum(labels == -1) / len(labels)
                    # Log parameters v√† metrics
                    mlflow.log_param("Model", "DBSCAN")
                    mlflow.log_param("eps", eps)
                    mlflow.log_param("min_samples", min_samples)
                    mlflow.log_metric("n_clusters", n_clusters)
                    mlflow.log_metric("Silhouette_score", silhouette)
                    mlflow.log_metric("noise_ratio", noise_ratio)
                    mlflow.log_metric("Training_time", training_time)

                    col1, col2, col3 = st.columns([1, 3, 1])
                    # V·∫Ω ph√¢n b·ªë c·ª•m
                    with col2:
                        # V·∫Ω ph√¢n b·ªë c·ª•m
                        visualize_dbscan()
                    #     plot_clusters(X_train_norm, labels, "DBSCAN",
                    #                   {"eps": eps, "min_samples": min_samples}, True)
                    # compare_clusters_with_true_labels(
                    #     X_train, y_train, labels, "DBSCAN")

                    st.success(
                        f"‚úÖ Hu·∫•n luy·ªán DBSCAN ho√†n t·∫•t! Th·ªùi gian: {training_time:.2f}s")
                    st.success(f"S·ªë c·ª•m t√¨m ƒë∆∞·ª£c: {n_clusters}")
                    st.success(f"T·ª∑ l·ªá nhi·ªÖu: {noise_ratio}")
                    st.success(f"Silhouette Score: {silhouette:.4f}")

            model_name = model_choice.lower().replace(" ", "_")
            count = 1
            new_model_name = model_name
            while any(m["name"] == new_model_name for m in st.session_state["models"]):
                new_model_name = f"{model_name}_{count}"
                count += 1

            st.session_state["models"].append(
                {"name": new_model_name, "model": model})
            st.write(f"üîπ **M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v·ªõi t√™n:** `{new_model_name}`")
