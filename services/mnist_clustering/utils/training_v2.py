import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import streamlit as st
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
import os
import mlflow


def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/lbnm203/Machine_Learning_UI.mlflow"
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    os.environ["MLFLOW_TRACKING_USERNAME"] = "lbnm203"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "0902d781e6c2b4adcd3cbf60e0f288a8085c5aab"

    mlflow.set_experiment("MNIST_Clustering")


# H√†m v·∫Ω bi·ªÉu ƒë·ªì scatter plot 2D
def plot_clusters(X_2d, dbscan_labels, kmeans_labels):
    """V·∫Ω bi·ªÉu ƒë·ªì scatter plot 2D cho k·∫øt qu·∫£ ph√¢n c·ª•m c·ªßa DBSCAN v√† Kmeans."""
    fig, ax = plt.subplots(1, 2, figsize=(12, 6))

    # Bi·ªÉu ƒë·ªì DBSCAN
    ax[0].scatter(X_2d[:, 0], X_2d[:, 1], c=dbscan_labels, cmap='viridis', s=5)
    ax[0].set_title("Ph√¢n c·ª•m DBSCAN")

    # Bi·ªÉu ƒë·ªì Kmeans
    ax[1].scatter(X_2d[:, 0], X_2d[:, 1], c=kmeans_labels, cmap='viridis', s=5)
    ax[1].set_title("Ph√¢n c·ª•m Kmeans")

    return fig


@st.cache_resource
def train_kmeans(X, n_clusters, max_iter):
    # ƒê·∫£m b·∫£o X l√† 2D
    if len(X.shape) > 2:
        X = X.reshape(-1, X.shape[1] * X.shape[2])
    kmeans = KMeans(n_clusters=n_clusters, max_iter=max_iter, random_state=42)
    labels = kmeans.fit_predict(X)
    return kmeans, labels


def plot_cluster_kmeans(X, n_clusters):
    fig, ax = plt.subplots(figsize=(6, 6))
    labels = st.session_state["labels"]
    centroids = st.session_state["centroids"]

    # ƒê·∫£m b·∫£o X l√† 2D tr∆∞·ªõc khi v·∫Ω
    if len(X.shape) > 2:
        X = X.reshape(-1, X.shape[1] * X.shape[2])

    # L·∫•y m·∫´u ng·∫´u nhi√™n 1000 ƒëi·ªÉm ƒë·ªÉ v·∫Ω
    if X.shape[0] > 1000:
        idx = np.random.choice(X.shape[0], 1000, replace=False)
        X_sample = X[idx]
        labels_sample = labels[idx]
    else:
        X_sample = X
        labels_sample = labels

    # V·∫Ω t·ª´ng c·ª•m (d√πng 2 chi·ªÅu ƒë·∫ßu ti√™n)
    for i in range(n_clusters):
        ax.scatter(X_sample[labels_sample == i][:, 0], X_sample[labels_sample == i][:, 1],
                   label=f"C·ª•m {i}", alpha=0.6, edgecolors="k")

    ax.scatter(centroids[:, 0], centroids[:, 1], s=200,
               c="red", marker="X", label="T√¢m c·ª•m")
    ax.set_title(f"K-Means Clustering")
    ax.legend()
    st.pyplot(fig)


def train_process(X, y):
    st.write("Qu√° tr√¨nh hu·∫•n luy·ªán")

    total_samples = X.shape[0]

    # Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train
    num_samples = st.slider(
        'Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh cho ph·∫ßn hu·∫•n luy·ªán', 1000, total_samples, 70000)
    X_selected, y_selected = X[:num_samples], y[:num_samples]

    # Ch·ªçn t·ª∑ l·ªá train/test
    test_size = st.slider('Test size', 0.0, 1.0, 0.3)

    if st.button("Chia D·ªØ Li·ªáu"):
        with st.spinner("ƒêang t·∫£i v√† chia d·ªØ li·ªáu..."):
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y_selected, test_size=test_size, random_state=42)
            st.success("üëâ Chia D·ªØ Li·ªáu Th√†nh C√¥ng!")

            # Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng m·∫´u
            st.write("### S·ªë l∆∞·ª£ng m·∫´u")
            data = {
                "T·∫≠p": ["Train", "Test"],
                "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_test.shape[0]],
                "T·ª∑ l·ªá (%)": [int((1 - test_size) * 100), int(test_size * 100)]
            }
            st.table(data)

            # L∆∞u v√†o session state
            # st.session_state['X_train'] = X_train
            # st.session_state['X_test'] = X_test
            # Chu·∫©n h√≥a d·ªØ li·ªáu
            st.session_state['X_train'] = X_train
            st.session_state['X_test'] = X_test
            st.session_state['y_train'] = y_train
            st.session_state['y_test'] = y_test

            # Chu·∫©n h√≥a d·ªØ li·ªáu
            st.session_state['X_train'] = X_train.reshape(-1, 28 * 28) / 255.0
            st.session_state['X_test'] = X_test.reshape(-1, 28 * 28) / 255.0

    X_train = st.session_state["X_train"]
    y_train = st.session_state["y_train"]

    st.write('---')
    model_type = st.selectbox('Ch·ªçn Thu·∫≠t To√°n Ph√¢n C·ª•m', ('KMeans', 'DBSCAN'))
    st.write('---')

    col1, col2 = st.columns(2)
    if model_type == "KMeans":
        with col1:
            n_clusters = st.slider("S·ªë c·ª•m (K)", 1, 10,
                                   10, help="S·ªë l∆∞·ª£ng t√¢m c·∫ßn t·∫°o ra")
            max_iter = st.slider("Max iterations", 100, 1000, 100,
                                 help="S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa c·ªßa thu·∫≠t to√°n k-means cho m·ªôt l·∫ßn ch·∫°y duy nh·∫•t")

            if st.button("Hu·∫•n luy·ªán KMeans"):
                if "X_train" not in st.session_state:
                    st.warning("‚ö†Ô∏è Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc khi train!")
                    return
                kmeans, kmeans_labels = train_kmeans(
                    X_train, n_clusters, max_iter)
                st.session_state["labels"] = kmeans_labels
                st.session_state["centroids"] = kmeans.cluster_centers_
                st.success("Hu·∫•n luy·ªán KMeans th√†nh c√¥ng!")

                # Logging MLflow
                with mlflow.start_run(run_name="KMeans_Training"):
                    mlflow.log_param("Clustering_Algorithm", "KMeans")
                    mlflow.log_param("n_clusters", n_clusters)
                    mlflow.log_param("max_iter", max_iter)
                    if len(np.unique(kmeans_labels)) > 1:
                        silhouette_kmeans = silhouette_score(
                            X_train, kmeans_labels)
                        mlflow.log_metric(
                            "Silhouette_Score_KMeans", silhouette_kmeans)
                        st.success(
                            f"Silhouette Score: {silhouette_kmeans:.4f}")
                    else:
                        st.warning(
                            "Kh√¥ng th·ªÉ t√≠nh Silhouette Score (ch·ªâ c√≥ 1 c·ª•m)")

        with col2:
            if "labels" in st.session_state:
                plot_cluster_kmeans(X_train, n_clusters)
            else:
                st.info("Ch∆∞a c√≥ d·ªØ li·ªáu c·ª•m ƒë·ªÉ v·∫Ω. Vui l√≤ng hu·∫•n luy·ªán tr∆∞·ªõc.")


#     elif model_type == "DBSCAN":
#         st.markdown("""
#         - **Epsilon (Œµ)**: gi√∫p x√°c ƒë·ªãnh c√°c ƒëi·ªÉm n·∫±m trong v√πng l√¢n c·∫≠n epsilon.""",
#         help="""
# - **Epsilon (Œµ)** th·∫•p c√≥ th·ªÉ d·∫´n ƒë·∫øn:
# - v√πng l√¢n c·∫≠n c·ªßa m·ªói ƒëi·ªÉm r·∫•t nh·ªè, d·∫´n ƒë·∫øn √≠t ƒëi·ªÉm ƒë∆∞·ª£c coi l√† l√¢n c·∫≠n c·ªßa nhau
# - Nhi·ªÅu ƒëi·ªÉm c√≥ th·ªÉ b·ªã coi l√† nhi·ªÖu (noise) v√¨ kh√¥ng ƒë·ªß ƒëi·ªÉm trong v√πng l√¢n c·∫≠n
# - C√°c c·ª•m c√≥ th·ªÉ b·ªã chia nh·ªè th√†nh nhi·ªÅu c·ª•m nh·ªè ho·∫∑c th·∫≠m ch√≠ kh√¥ng h√¨nh th√†nh c·ª•m n√†o.

# ‚Üí S·ªë l∆∞·ª£ng c·ª•m tƒÉng l√™n, nhi·ªÅu ƒëi·ªÉm b·ªã g√°n nh√£n l√† nhi·ªÖu.
# - **Epsilon (Œµ)** cao c√≥ th·ªÉ d·∫´n ƒë·∫øn:
# - V√πng l√¢n c·∫≠n c·ªßa m·ªói ƒëi·ªÉm r·∫•t l·ªõn, d·∫´n ƒë·∫øn nhi·ªÅu ƒëi·ªÉm ƒë∆∞·ª£c coi l√† l√¢n c·∫≠n c·ªßa nhau
# - C√°c c·ª•m c√≥ th·ªÉ b·ªã h·ª£p nh·∫•t th√†nh m·ªôt c·ª•m l·ªõn, ngay c·∫£ khi ch√∫ng kh√¥ng th·ª±c s·ª± thu·ªôc c√πng m·ªôt c·ª•m.

# ‚Üí S·ªë l∆∞·ª£ng c·ª•m gi·∫£m xu·ªëng, c√≥ th·ªÉ ch·ªâ c√≤n m·ªôt c·ª•m duy nh·∫•t, √≠t ƒëi·ªÉm b·ªã g√°n nh√£n l√† nhi·ªÖu.""")

#         st.markdown("""
#         - **Min_samples**: S·ªë l∆∞·ª£ng ƒëi·ªÉm t·ªëi thi·ªÉu trong v√πng l√¢n c·∫≠n Œµ ƒë·ªÉ m·ªôt ƒëi·ªÉm ƒë∆∞·ª£c coi l√† ƒëi·ªÉm l√µi (core point).""",
#         help="""
# - **Min_samples** th·∫•p c√≥ th·ªÉ d·∫´n ƒë·∫øn:
# - R·∫•t d·ªÖ ƒë·ªÉ m·ªôt ƒëi·ªÉm tr·ªü th√†nh ƒëi·ªÉm l√µi, ngay c·∫£ khi n√≥ n·∫±m trong v√πng c√≥ m·∫≠t ƒë·ªô th·∫•p.
# - C√°c c·ª•m c√≥ th·ªÉ ch·ª©a nhi·ªÅu ƒëi·ªÉm nhi·ªÖu ho·∫∑c kh√¥ng ƒë·ªìng nh·∫•t.
# ‚Üí S·ªë l∆∞·ª£ng c·ª•m tƒÉng l√™n, c√°c c·ª•m c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c v√† ch·ª©a nhi·ªÅu nhi·ªÖu.
# - **Min_samples** cao c√≥ th·ªÉ d·∫´n ƒë·∫øn:
# - Kh√≥ ƒë·ªÉ m·ªôt ƒëi·ªÉm tr·ªü th√†nh ƒëi·ªÉm l√µi, v√¨ c·∫ßn nhi·ªÅu ƒëi·ªÉm trong v√πng l√¢n c·∫≠n.
# - C√°c c·ª•m c√≥ th·ªÉ b·ªã b·ªè s√≥t, ƒë·∫∑c bi·ªát l√† c√°c c·ª•m nh·ªè ho·∫∑c c√≥ m·∫≠t ƒë·ªô th·∫•p.
# ‚Üí S·ªë l∆∞·ª£ng c·ª•m gi·∫£m xu·ªëng, nhi·ªÅu ƒëi·ªÉm b·ªã g√°n nh√£n l√† nhi·ªÖu, ngay c·∫£ khi ch√∫ng thu·ªôc v·ªÅ m·ªôt c·ª•m th·ª±c s·ª±.
# """)
#         st.markdown("""
#         - **metric**: H√†m kho·∫£ng c√°ch ƒë·ªÉ ƒëo l∆∞·ªùng kho·∫£ng c√°ch gi·ªØa hai ƒëi·ªÉm b·∫•t k√¨""",
#         help="""m·∫∑c ƒë·ªãnh l√† euclidean""")

#         st.markdown("""
#         - **algorithm**: ph∆∞∆°ng ph√°p ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ x√°c ƒë·ªãnh c√°c ƒëi·ªÉm l√°ng gi·ªÅng""",
#         help="""Bao g·ªìm c√°c ph∆∞∆°ng ph√°p auto, ball_tree, kd_tree, brute:
# - `auto`: DBSCAN t·ª± ƒë·ªông ch·ªçn thu·∫≠t to√°n t·ªëi ∆∞u d·ª±a tr√™n ƒë·∫∑c ƒëi·ªÉm c·ªßa d·ªØ li·ªáu (v√≠ d·ª•: s·ªë chi·ªÅu, s·ªë l∆∞·ª£ng ƒëi·ªÉm d·ªØ li·ªáu).
# N√≥ s·∫Ω ∆∞u ti√™n s·ª≠ d·ª•ng kd_tree ho·∫∑c ball_tree n·∫øu d·ªØ li·ªáu ph√π h·ª£p, ng∆∞·ª£c l·∫°i s·∫Ω s·ª≠ d·ª•ng brute.
# - `ball_tree`: S·ª≠ d·ª•ng c·∫•u tr√∫c d·ªØ li·ªáu Ball Tree ƒë·ªÉ t·ªï ch·ª©c c√°c ƒëi·ªÉm d·ªØ li·ªáu trong kh√¥ng gian.
# Ball Tree chia kh√¥ng gian th√†nh c√°c h√¨nh c·∫ßu (balls) l·ªìng nhau, gi√∫p t√¨m ki·∫øm l√¢n c·∫≠n hi·ªáu qu·∫£ h∆°n trong kh√¥ng gian nhi·ªÅu chi·ªÅu.
# S·ª≠ d·ª•ng khi d·ªØ li·ªáu c√≥ s·ªë chi·ªÅu cao (high-dimensional data) v√† kd_tree kh√¥ng hi·ªáu qu·∫£.
# - `kd_tree`: S·ª≠ d·ª•ng c·∫•u tr√∫c d·ªØ li·ªáu KD-Tree (K-dimensional Tree) ƒë·ªÉ t·ªï ch·ª©c c√°c ƒëi·ªÉm d·ªØ li·ªáu.
# KD-Tree chia kh√¥ng gian th√†nh c√°c v√πng h√¨nh ch·ªØ nh·∫≠t d·ª±a tr√™n c√°c tr·ª•c t·ªça ƒë·ªô. S·ª≠ d·ª•ng khi d·ªØ li·ªáu c√≥ s·ªë chi·ªÅu th·∫•p ƒë·∫øn trung b√¨nh
# (th∆∞·ªùng d∆∞·ªõi 20 chi·ªÅu).
# - `brute`: S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p v√©t c·∫°n (brute-force) ƒë·ªÉ t√≠nh to√°n kho·∫£ng c√°ch gi·ªØa t·∫•t c·∫£ c√°c c·∫∑p ƒëi·ªÉm.
# Kh√¥ng s·ª≠ d·ª•ng b·∫•t k·ª≥ c·∫•u tr√∫c d·ªØ li·ªáu n√†o ƒë·ªÉ t·ªëi ∆∞u h√≥a t√¨m ki·∫øm. S·ª≠ d·ª•ng khi d·ªØ li·ªáu c√≥ s·ªë chi·ªÅu r·∫•t cao ho·∫∑c khi c√°c thu·∫≠t to√°n kh√°c kh√¥ng hi·ªáu qu·∫£.
# """)

#         eps = st.slider("Epsilon", 0.1, 5.0, 1.0)
#         min_samples = st.slider("Min Samples", 2, 20, 5)
#         metric = st.selectbox("Metric", ["euclidean", "manhattan"])
#         algorithm = st.selectbox("Algorithm", ["auto", "ball_tree", "kd_tree", "brute"])
#         dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric=metric, algorithm=algorithm)

#         if st.button("Hu·∫•n luy·ªán DBSCAN"):
#             dbscan_labels = dbscan.fit_predict(X)
#             st.session_state["dbscan_labels"] = dbscan_labels
#             st.success("Hu·∫•n luy·ªán DBSCAN th√†nh c√¥ng!")

#             # Logging MLflow
#             mlflow.log_param("Clustering_Algorithm", "DBSCAN")
#             mlflow.log_param("eps", eps)
#             mlflow.log_param("min_samples", min_samples)
#             mlflow.log_param("metric", metric)
#             mlflow.log_param("algorithm", algorithm)

#             st.markdown("Silhouette Score", help="""
# - Silhouette Score l√† m·ªôt ch·ªâ s·ªë ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng c·ªßa c√°c c·ª•m (clusters) trong ph√¢n c·ª•m d·ªØ li·ªáu.
# N√≥ ƒëo l∆∞·ªùng m·ª©c ƒë·ªô t∆∞∆°ng ƒë·ªìng c·ªßa m·ªôt ƒëi·ªÉm d·ªØ li·ªáu v·ªõi c√°c ƒëi·ªÉm trong c√πng c·ª•m so v·ªõi c√°c ƒëi·ªÉm trong
# c√°c c·ª•m kh√°c. Gi√° tr·ªã Silhouette Score n·∫±m trong kho·∫£ng t·ª´ -1 ƒë·∫øn 1, trong ƒë√≥:
# - Gi√° tr·ªã c√†ng g·∫ßn 1: C√°c c·ª•m c√†ng t·ªët, ƒëi·ªÉm d·ªØ li·ªáu ƒë∆∞·ª£c g√°n ƒë√∫ng c·ª•m.
# - Gi√° tr·ªã g·∫ßn 0: ƒêi·ªÉm d·ªØ li·ªáu n·∫±m g·∫ßn ranh gi·ªõi gi·ªØa hai c·ª•m.
# - Gi√° tr·ªã √¢m: ƒêi·ªÉm d·ªØ li·ªáu c√≥ th·ªÉ b·ªã g√°n sai c·ª•m.
# """)
#             # ƒê√°nh gi√° DBSCAN
#             if len(np.unique(dbscan_labels)) > 1:
#                 mask = dbscan_labels != -1
#                 X_no_noise = X_train[mask]
#                 labels_no_noise = dbscan_labels[mask]
#                 if len(np.unique(labels_no_noise)) > 1:
#                     silhouette_dbscan = silhouette_score(
#                         X_no_noise, labels_no_noise)
#                     mlflow.log_metric("Silhouette_Score_DBSCAN", silhouette_dbscan)
#                     st.success(
#                         f"Silhouette Score (kh√¥ng t√≠nh nhi·ªÖu): {silhouette_dbscan:.4f}")
#                 else:
#                     st.warning(
#                         "Kh√¥ng th·ªÉ t√≠nh Silhouette Score (ch·ªâ c√≥ 1 c·ª•m sau khi lo·∫°i nhi·ªÖu)")
#             else:
#                 st.warning(
#                     "Kh√¥ng th·ªÉ t√≠nh Silhouette Score (ch·ªâ c√≥ 1 c·ª•m ho·∫∑c to√†n nhi·ªÖu)")

#             with col2:
#                 # # Gi·∫£m chi·ªÅu xu·ªëng 2D ƒë·ªÉ v·∫Ω
#                 # if use_pca and n_components != 2:
#                 #     X_train_2d = reduce_dimension(X_train, 2)
#                 # else:
#                 #     X_train_2d = X_train_reduced

#                 # V·∫Ω bi·ªÉu ƒë·ªì
#                 st.write("#### K·∫øt qu·∫£ ph√¢n c·ª•m DBSCAN")
#                 fig, ax = plt.subplots(figsize=(6, 6))
#                 ax.scatter(X_train[:, 0], X_train[:, 1],
#                         c=dbscan_labels, cmap='viridis', s=5)
#                 ax.set_title("Ph√¢n c·ª•m DBSCAN")
#                 ax.set_xticks([])
#                 ax.set_yticks([])
#                 st.pyplot(fig)
